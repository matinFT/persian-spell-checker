{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82306554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import parsivar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from polyleven import levenshtein\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6edf97d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = parsivar.Normalizer()\n",
    "tokenizer = parsivar.Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73562a91",
   "metadata": {},
   "source": [
    "# Keyhan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aeb9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"Keyhan.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0daf8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n",
      "['\\n', ' ', '!', '(', ')', '.', ':', '«', '\\xad', '»', '،', '؟', 'ء', 'آ', 'أ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'ً', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ۀ', 'ی', '۰', '۱', '۳', '۵', '۹', '\\u200c', '1', '2', '3', '6', '8', '9', '[', ']', 'ـ', 'ك', 'ي', '۲', '۴', '\\u202c', '\\u202d', '\\u202e', '؛', 'ؤ', 'ُ', 'ِ', '۷', '۸', '4', '|', 'إ', 'ة', 'ى', 'ٌ', 'ٍ', 'َ', 'ّ', 'ْ', '٤', '٧', '-', '٪', '\\u202b', '5', '7', '0', '۶', '#', '@', '_', 'a', 'd', 'e', 'f', 'i', 'j', 'm', 'n', 'r', 'y', 'A', 'I', 'N', 'U', '–', '=', '١', '٥', '٦', '٨', '*', '/', 'E', 'H', 'K', 'M', 'R', '%', 'B', 'C', 'G', 'O', 'F', '٫', '+', 'P', 'S', 'D', 'L', 'W', 'c', 'g', 'k', 'l', 'o', 'p', 't', 'u', 'v', 'w', 'T', 'b', 'h', 's', '٠', 'Ε', 'Ι', '٢', 'V', 'x', 'Z', '…', '?', 'Y', '\\u200d', '٣', '٩', 'J', '️', 'X', 'Q', '&', ',', 'z', 'ٔ', 'q', '×', ';', 'ʳ', 'ᵉ', 'ᵒ', 'ᵛ', 'ᶠ', '⁷', '\"', 'ﭙ', 'ﭼ', 'ﮐ', 'ﮑ', 'ﮓ', 'ﮔ', 'ﮕ', 'ﯽ', 'ﯾ', 'ﯿ', 'ﺎ', 'ﺑ', 'ﺒ', 'ﺖ', 'ﺗ', 'ﺘ', 'ﺛ', 'ﺟ', 'ﺣ', 'ﺤ', 'ﺧ', 'ﺪ', 'ﺬ', 'ﺮ', 'ﺰ', 'ﺳ', 'ﺴ', 'ﺶ', 'ﺷ', 'ﺸ', 'ﺻ', 'ﺿ', 'ﻀ', 'ﻈ', 'ﻊ', 'ﻋ', 'ﻌ', 'ﻏ', 'ﻓ', 'ﻔ', 'ﻗ', 'ﻘ', 'ﻛ', 'ﻜ', 'ﻞ', 'ﻟ', 'ﻠ', 'ﻣ', 'ﻤ', 'ﻦ', 'ﻧ', 'ﻨ', 'ﻮ', 'ﻲ', 'ﻻ', 'ﻼ', '’', 'ٱ', '\\u200a', '`', '\\u202a', 'ﺋ', '“', '”', '٬', '{', '}', '›', 'ﷲ', 'ﭘ', 'ﮋ', 'ﺠ', 'ﻂ', 'ﻇ', 'ﻪ', 'ﻫ', 'ﻬ', '\\x05', 'ﺍ', 'ﺙ', 'ﺚ', 'ﺩ', 'ﺭ', 'ﺯ', 'ﻡ', 'ﻢ', 'ﻥ', 'ﻭ', 'ﻳ', 'ﻴ', 'ﺨ', 'ö', '÷', '\\u2005', 'é', '﴾', '﴿', '‘', 'ﺼ', 'ﻄ', 'ۂ', '‹', 'ٰ', 'ﺌ', 'ﺐ', 'ﻚ', 'ﻰ', '$', 'ü', 'ﮊ', 'Î', 'İ', '\\ue825', 'è', 'ş', '\\uf03d', 'å', 'ﭻ', 'ﺄ', 'ﺦ', 'ﺲ', 'ﻃ', 'ﻐ', 'ﻖ', 'ﯼ', 'ﺁ', 'ﺏ', 'ﺕ', 'ﺵ', 'ﻍ', 'ﻑ', 'ﻕ', 'ﻩ', \"'\", '✓', '±', '•', '\\u2001', 'ó', '\\u2009', 'â', '—', 'ï', '¬', '°', '‑', 'ﭗ', 'ﭽ', '>', '\\\\', 'ﺢ', 'ﺺ', 'ﻆ', 'ﻒ']\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uniques = []\n",
    "content = None\n",
    "for key in data:\n",
    "    content = data[key][\"content\"]\n",
    "    uniques.extend([x for x in np.unique([y for y in content]) if x not in uniques]) \n",
    "print(len(uniques))\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c0f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "['\\n', ' ', '!', '(', ')', '.', '0', '1', '3', '5', '9', ':', '«', '\\xad', '»', '،', '؟', 'آ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی', '\\u200c', '2', '4', '6', '8', '[', ']', '7', '؛', '|', 'ّ', 'ْ', '-', '٪', '#', '@', '_', 'a', 'd', 'e', 'f', 'i', 'j', 'm', 'n', 'r', 'y', 'A', 'I', 'N', 'U', '=', '٥', '*', '/', 'E', 'H', 'K', 'M', 'R', '%', 'B', 'C', 'G', 'O', 'F', '+', 'P', 'S', 'D', 'L', 'W', 'c', 'g', 'k', 'l', 'o', 'p', 't', 'u', 'v', 'w', 'T', 'b', 'h', 's', 'Ε', 'Ι', 'V', 'x', 'Z', '?', 'Y', 'J', 'X', 'Q', '&', 'z', 'ٔ', 'q', '×', ';', 'ʳ', '\"', '\\u200a', '`', '{', '}', 'ö', '÷', '\\u2005', 'é', 'ۂ', 'ٰ', '$', 'ü', 'Î', 'İ', 'è', 'ş', 'å', \"'\", '±', '\\u2001', 'ó', '\\u2009', 'â', 'ï', '°', '>', '\\\\']\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uniques = []\n",
    "content = None\n",
    "for key in data:\n",
    "    content = data[key][\"content\"]\n",
    "    uniques.extend([x for x in np.unique([y for y in normalizer.normalize(content)]) if x not in uniques])    \n",
    "print(len(uniques))\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6605c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حالت­خوبه\n",
      "حالت‌خوبه\n",
      "حالت خوبه\n",
      "حالت خوبه\n",
      "حالت خوبه\n",
      "حالت خوبه\n"
     ]
    }
   ],
   "source": [
    "print(\"حالت\"+\"\\xad\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u200c\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u200a\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u2001\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u2005\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u2009\"+\"خوبه\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e858cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\n",
    "    \"\\xad\":\"\",\n",
    "    \"\\u200a\":\" \",\n",
    "    \"\\u2001\":\" \",\n",
    "    \"\\u2005\":\" \",\n",
    "    \"\\u2009\":\" \",\n",
    "    \"ۂ\":\n",
    "        \"ه\",\n",
    "    \"ئ\": \n",
    "        \"ی\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47cc1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_characters = [0,1,2,3,4,5,6,7,8,9,\n",
    "                       \"و\", \"ن\", \"م\", \"ل\", \"گ\", \"ک\", \"ق\", \"ف\", \"غ\", \"ع\", \"ظ\", \"ط\", \"ض\", \"ص\", \"ی\", \"ه\",\n",
    "                       \"ش\", \"س\", \"ژ\", \"ز\", \"ر\", \"ذ\", \"د\", \"خ\", \"ح\", \"چ\", \"ج\", \"ث\", \"ت\", \"پ\", \"ب\", \"ا\", \"آ\",\n",
    "                       \" \", \"\\u200c\", \"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "858abbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 0\n",
    "f = open(\"test.txt\", \"w\", encoding='utf-8')\n",
    "for key in data:\n",
    "    for x in tokenizer.tokenize_sentences(normalizer.normalize(data[key][\"content\"].replace(\"\\n\", \".\"))):\n",
    "        res = \"\"\n",
    "        for character in x:\n",
    "            if character not in accepted_characters:\n",
    "                if character in replace_dict:\n",
    "                    res += replace_dict[character]\n",
    "            else:\n",
    "                res += character\n",
    "        f.write(res+\"\\n\")\n",
    "#         f.write(x+\"\\n\")\n",
    "        \n",
    "#     i += 1\n",
    "#     if i == 1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d760981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62500 posts\n",
      "169469780 characters\n",
      "1309619 lines\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(data)} posts')\n",
    "f = open(\"test.txt\", \"r\", encoding='utf-8')\n",
    "number_of_chars = len(f.read())\n",
    "print(f'{number_of_chars} characters')\n",
    "f.close()\n",
    "f = open(\"test.txt\", \"r\", encoding='utf-8')\n",
    "number_of_lines = len(f.readlines())\n",
    "print(f'{number_of_lines} lines')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8882ea9f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_uniques = []\n",
    "content = None\n",
    "with open(\"test.txt\", \"r\", encoding='utf-8') as t:\n",
    "    while True:\n",
    "        content = t.readline()\n",
    "        if content == \"\":\n",
    "            break\n",
    "        text_uniques.extend([x for x in np.unique([y for y in content]) if x not in text_uniques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bf87351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "['\\n', ' ', 'آ', 'ا', 'ت', 'ح', 'خ', 'د', 'ر', 'ز', 'س', 'ش', 'ع', 'ل', 'م', 'ن', 'ه', 'و', 'پ', 'چ', 'ک', 'ی', 'ب', 'ج', 'ص', 'غ', 'ف', 'ق', 'ذ', '\\u200c', 'ث', 'ض', 'ط', 'ژ', 'گ', 'ظ', '-']\n"
     ]
    }
   ],
   "source": [
    "print(len(text_uniques))\n",
    "print(text_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe961752",
   "metadata": {},
   "source": [
    "# Hamshahri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04f96ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346\n"
     ]
    }
   ],
   "source": [
    "data2 = json.load(open(\"Hamshahri.json\", \"r\"))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67096b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "uniques = []\n",
    "content = None\n",
    "for key in data2:\n",
    "    for key2 in data2[key][\"posts\"]:\n",
    "        content = data2[key][\"posts\"][key2]\n",
    "        uniques.extend([x for x in np.unique([y for y in normalizer.normalize(content)]) if x not in uniques])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46caf6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "['\\n', ' ', '-', '.', '0', '1', '2', '3', '4', '5', '7', '8', '9', ':', '«', '»', '،', '؛', 'آ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی', '\\u200c', '(', ')', '6', 'ذ', 'غ', 'E', 'T', 'U', 'S', '؟', '!', 'a', 'c', 'm', 's', 'A', 'B', 'J', 'M', 'N', 'O', 'R', 'V', 'e', 'i', 'n', 'p', '*', 'C', '/', 'F', 'D', 'P', 'ّ', 'd', 'f', 'h', 'k', 'l', 'o', 'r', 't', 'g', 'x', 'z', 'L', '#', 'I', 'Q', '+', 'W', '[', ']', '&', 'u', 'H', 'K', 'X', 'G', '\\u2009', 'v', 'y', 'b', '_', 'ٓ', '٥', 'ْ', '\\xad', 'Z', 'Y', 'w', '%', 'j', '@', '|', 'q', '\\u200a', 'í', '×', '{', '}', '>', '=', 'è', '?', 'é', \"'\", 'ٰ', 'ٔ', 'à', 'ç', 'ê', 'İ', 'ş', '\"', ';', 'ۆ', '\\\\', '٪', '\\x81', '\\u2005']\n"
     ]
    }
   ],
   "source": [
    "print(len(uniques))\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c61b01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\n",
    "    \"\\xad\":\"\",\n",
    "    \"\\u200a\":\" \",\n",
    "    \"\\u2001\":\" \",\n",
    "    \"\\u2005\":\" \",\n",
    "    \"\\u2009\":\" \",\n",
    "    \"ۂ\":\n",
    "        \"ه\",\n",
    "    \"ئ\": \n",
    "        \"ی\",\n",
    "    \"٥\":\n",
    "        \"5\",\n",
    "    \"ۆ\": \n",
    "        \"و\",\n",
    "    \n",
    "}\n",
    "accepted_characters = [0,1,2,3,4,5,6,7,8,9,\n",
    "                       \"و\", \"ن\", \"م\", \"ل\", \"گ\", \"ک\", \"ق\", \"ف\", \"غ\", \"ع\", \"ظ\", \"ط\", \"ض\", \"ص\", \"ی\", \"ه\",\n",
    "                       \"ش\", \"س\", \"ژ\", \"ز\", \"ر\", \"ذ\", \"د\", \"خ\", \"ح\", \"چ\", \"ج\", \"ث\", \"ت\", \"پ\", \"ب\", \"ا\", \"آ\",\n",
    "                       \" \", \"\\u200c\", \"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "470522ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حالت­خوبه\n",
      "حالتخوبه\n",
      "حالت‌خوبه\n",
      "حالت‍خوبه\n",
      "حالت‫خوبه\n",
      "حالت‬خوبه\n",
      "حالت خوبه\n",
      "حالت‪خوبه\n",
      "حالت خوبه\n",
      "حالت خوبه\n"
     ]
    }
   ],
   "source": [
    "print(\"حالت\"+\"\\xad\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\x81\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u200c\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u200d\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u202b\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u202c\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u200a\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u202a\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u2005\"+\"خوبه\")\n",
    "print(\"حالت\"+\"\\u2009\"+\"خوبه\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6114cc2d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f = open(\"test.txt\", \"a\", encoding='utf-8')\n",
    "# i = 0\n",
    "for key in data2:\n",
    "    for k in data2[key][\"posts\"]:\n",
    "        for x in tokenizer.tokenize_sentences(normalizer.normalize(data2[key][\"posts\"][k].replace(\"\\n\", \" .\"))):\n",
    "            res = \"\"\n",
    "            for character in x:\n",
    "                if character not in accepted_characters:\n",
    "                    if character in replace_dict:\n",
    "                        res += replace_dict[character]\n",
    "                else:\n",
    "                    res += character\n",
    "            f.write(res+\"\\n\")\n",
    "#     i += 1\n",
    "#     if i == 20:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bbe755",
   "metadata": {},
   "source": [
    "# build ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c123b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "word2vec_model = Word2Vec.load(\"Word2VecModel\")\n",
    "# FastText_model = FastText.load(\"FastTextModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07d6a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_tuple(words, model):\n",
    "    return tuple([model.wv.key_to_index[words[i]] for i in range(len(words))])\n",
    "\n",
    "# seems some of the words in the text file is not present in model key_to_index\n",
    "def build_ngrams(n):\n",
    "    ngram_counts = {}\n",
    "    with open(\"test.txt\", \"r\", encoding='utf-8') as t:\n",
    "        while True:\n",
    "            line = t.readline()\n",
    "            if line == \"\":\n",
    "                break\n",
    "            words = tokenizer.tokenize_words(line)\n",
    "            for i in range(max(len(words)-n+1, 0)):\n",
    "                try:\n",
    "#                     pre_words_indices = tuple([word2vec_model.wv.key_to_index[words[i+j]] for j in range(n)])\n",
    "                    pre_words_indices = words_to_tuple(words[i:i+n], word2vec_model)\n",
    "                    if pre_words_indices in ngram_counts:\n",
    "                        ngram_counts[pre_words_indices] += 1\n",
    "                    else:\n",
    "                        ngram_counts[pre_words_indices] = 1\n",
    "                except:\n",
    "                    pass\n",
    "    return ngram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27283c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words counts:  46105696\n",
      "biword counts:  44176255\n",
      "threeword counts:  42284970\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_counts = build_ngrams(1)\n",
    "word_counts[\"all\"] = sum(word_counts.values())\n",
    "print(\"words counts: \", word_counts[\"all\"])\n",
    "# 100MB of RAM\n",
    "biword_counts = build_ngrams(2)\n",
    "biword_counts[\"all\"] = sum(biword_counts.values())\n",
    "print(\"biword counts: \", biword_counts[\"all\"])\n",
    "\n",
    "# 700MB of RAM\n",
    "threeword_counts = build_ngrams(3)\n",
    "threeword_counts[\"all\"] = sum(threeword_counts.values())\n",
    "print(\"threeword counts: \", threeword_counts[\"all\"])\n",
    "# 1.6GB of RAM\n",
    "fourword_counts = build_ngrams(4)\n",
    "fourword_counts[\"all\"] = sum(fourword_counts.values())\n",
    "print(\"fourword counts: \", fourword_counts[\"all\"])\n",
    "\n",
    "# 3.5GB of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45c6bc75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['منجر', 'به'],\n",
       " ['که', 'دولت'],\n",
       " ['آن', 'هم'],\n",
       " ['بیشتر', 'از'],\n",
       " ['بر', 'سر'],\n",
       " ['در', 'زمان'],\n",
       " ['در', 'برخی'],\n",
       " ['اینکه', 'در'],\n",
       " ['داده', 'و'],\n",
       " ['سازمان', 'ملل'],\n",
       " ['درصد', 'از'],\n",
       " ['با', 'یک'],\n",
       " ['این', 'حال'],\n",
       " ['کمتر', 'از'],\n",
       " ['خاطرنشان', 'کرد'],\n",
       " ['ندارد', 'و'],\n",
       " ['در', 'روز'],\n",
       " ['از', 'هزار'],\n",
       " ['که', 'یک'],\n",
       " ['و', 'مردم'],\n",
       " ['است', 'تا'],\n",
       " ['در', 'مجلس'],\n",
       " ['کار', 'را'],\n",
       " ['این', 'افراد'],\n",
       " ['در', 'راستای'],\n",
       " ['جلوگیری', 'از'],\n",
       " ['هم', 'با'],\n",
       " ['از', 'بین'],\n",
       " ['سال', 'در'],\n",
       " ['و', 'بر'],\n",
       " ['این', 'روزها'],\n",
       " ['نیاز', 'به'],\n",
       " ['در', 'جامعه'],\n",
       " ['و', 'پرورش'],\n",
       " ['خارج', 'از'],\n",
       " ['وی', 'ادامه'],\n",
       " ['و', 'هر'],\n",
       " ['دستور', 'کار'],\n",
       " ['و', 'ما'],\n",
       " ['سیاسی', 'و'],\n",
       " ['امور', 'خارجه'],\n",
       " ['رسیدن', 'به'],\n",
       " ['با', 'آن'],\n",
       " ['تا', 'پایان'],\n",
       " ['کرد', 'در'],\n",
       " ['و', 'پس'],\n",
       " ['از', 'هر'],\n",
       " ['به', 'خاطر'],\n",
       " ['گفتنی', 'است'],\n",
       " ['با', 'ایران'],\n",
       " ['به', 'کار'],\n",
       " ['ما', 'به'],\n",
       " ['به', 'ما'],\n",
       " ['و', 'همه'],\n",
       " ['شد', 'تا'],\n",
       " ['به', 'او'],\n",
       " ['صورت', 'گرفته'],\n",
       " ['اجتماعی', 'و'],\n",
       " ['در', 'آمریکا'],\n",
       " ['در', 'مسیر'],\n",
       " ['گرفت', 'و'],\n",
       " ['در', 'داخل'],\n",
       " ['در', 'روزهای'],\n",
       " ['در', 'دستور'],\n",
       " ['ایران', 'با'],\n",
       " ['باشد', 'که'],\n",
       " ['ایران', 'از'],\n",
       " ['داشته', 'باشیم'],\n",
       " ['آمریکا', 'به'],\n",
       " ['افزایش', 'قیمت'],\n",
       " ['چند', 'روز'],\n",
       " ['است', 'از'],\n",
       " ['و', 'دیگر'],\n",
       " ['میلیارد', 'دلار'],\n",
       " ['این', 'شرایط'],\n",
       " ['گرفته', 'و'],\n",
       " ['و', 'تا'],\n",
       " ['در', 'شرایطی'],\n",
       " ['ج', 'ص'],\n",
       " ['اقدام', 'به'],\n",
       " ['این', 'اتفاق'],\n",
       " ['روز', 'گذشته'],\n",
       " ['در', 'جلسه'],\n",
       " ['باید', 'با'],\n",
       " ['کردند', 'که'],\n",
       " ['خواهد', 'داشت'],\n",
       " ['کرده', 'که'],\n",
       " ['نیز', 'با'],\n",
       " ['در', 'دوره'],\n",
       " ['افرادی', 'که'],\n",
       " ['رهبر', 'انقلاب'],\n",
       " ['تهران', 'و'],\n",
       " ['همزمان', 'با'],\n",
       " ['اسلامی', 'در'],\n",
       " ['یافته', 'است'],\n",
       " ['و', 'چه'],\n",
       " ['که', 'هر'],\n",
       " ['یک', 'سال'],\n",
       " ['داشت', 'که'],\n",
       " ['نزدیک', 'به'],\n",
       " ['شود', 'که'],\n",
       " ['از', 'همه'],\n",
       " ['داشته', 'و'],\n",
       " ['سیاست', 'خارجی'],\n",
       " ['از', 'طرف'],\n",
       " ['در', 'همه'],\n",
       " ['ملت', 'ایران'],\n",
       " ['در', 'عین'],\n",
       " ['مردم', 'به'],\n",
       " ['نیز', 'از'],\n",
       " ['تا', 'در'],\n",
       " ['این\\u200cبود', 'که'],\n",
       " ['علیه', 'ایران'],\n",
       " ['این', 'اقدام'],\n",
       " ['در', 'مناطق'],\n",
       " ['دفاع', 'مقدس'],\n",
       " ['در', 'دوران'],\n",
       " ['در', 'ماه'],\n",
       " ['کنیم', 'و'],\n",
       " ['هم', 'که'],\n",
       " ['اما', 'با'],\n",
       " ['با', 'کرونا'],\n",
       " ['را', 'دارد'],\n",
       " ['و', 'نیز'],\n",
       " ['سال', 'جاری'],\n",
       " ['همچنین', 'در'],\n",
       " ['از', 'اینکه'],\n",
       " ['آن\\u200cها', 'به'],\n",
       " ['ایالات', 'متحده'],\n",
       " ['کشور', 'است'],\n",
       " ['که', 'بر'],\n",
       " ['سال', 'آینده'],\n",
       " ['و', 'سایر'],\n",
       " ['اعلام', 'کرده'],\n",
       " ['به', 'نقل'],\n",
       " ['و', 'برخی'],\n",
       " ['اسلامی', 'و'],\n",
       " ['امام', 'خمینی'],\n",
       " ['وزیر', 'خارجه'],\n",
       " ['معظم', 'انقلاب'],\n",
       " ['آمریکا', 'از'],\n",
       " ['اشاره', 'کرد'],\n",
       " ['نقل', 'از'],\n",
       " ['رهبر', 'معظم'],\n",
       " ['ایران', 'است'],\n",
       " ['از', 'او'],\n",
       " ['به', 'شکل'],\n",
       " ['گذشته', 'در'],\n",
       " ['سال', 'قبل'],\n",
       " ['که', 'تا'],\n",
       " ['نظر', 'می\\u200cرسد'],\n",
       " ['شدند', 'و'],\n",
       " ['فرهنگی', 'و'],\n",
       " ['به', 'ویژه'],\n",
       " ['بیان', 'کرد'],\n",
       " ['با', 'هدف'],\n",
       " ['در', 'دست'],\n",
       " ['از', 'کشور'],\n",
       " ['تولید', 'و'],\n",
       " ['مورد', 'نیاز'],\n",
       " ['سال', 'و'],\n",
       " ['به', 'شدت'],\n",
       " ['یک', 'میلیون'],\n",
       " ['است', 'این'],\n",
       " ['هر', 'دو'],\n",
       " ['آمریکا', 'را'],\n",
       " ['در', 'نتیجه'],\n",
       " ['رو', 'به'],\n",
       " ['در', 'تاریخ'],\n",
       " ['از', 'برجام'],\n",
       " ['اما', 'به'],\n",
       " ['در', 'جهان'],\n",
       " ['پیدا', 'کند'],\n",
       " ['لازم', 'است'],\n",
       " ['این', 'را'],\n",
       " ['همان\\u200cطور', 'که'],\n",
       " ['است', 'با'],\n",
       " ['بوده', 'که'],\n",
       " ['با', 'هم'],\n",
       " ['و', 'البته'],\n",
       " ['می\\u200cکنند', 'که'],\n",
       " ['باز', 'هم'],\n",
       " ['به', 'هزار'],\n",
       " ['بار', 'دیگر'],\n",
       " ['ما', 'از'],\n",
       " ['نه', 'تنها'],\n",
       " ['اتحادیه', 'اروپا'],\n",
       " ['و', 'دولت'],\n",
       " ['دو', 'کشور'],\n",
       " ['کسی', 'که'],\n",
       " ['با', 'استفاده'],\n",
       " ['حتی', 'در'],\n",
       " ['سال\\u200cهای', 'اخیر'],\n",
       " ['دولت', 'سیزدهم'],\n",
       " ['دولت', 'روحانی'],\n",
       " ['این', 'حوزه'],\n",
       " ['و', 'افزایش'],\n",
       " ['تعدادی', 'از'],\n",
       " ['به', 'پایان'],\n",
       " ['زیادی', 'از'],\n",
       " ['گفت', 'این'],\n",
       " ['انجام', 'می\\u200cشود'],\n",
       " ['دفاع', 'از'],\n",
       " ['به\\u200cنظر', 'می\\u200cرسد'],\n",
       " ['که', 'مردم'],\n",
       " ['ملی', 'و'],\n",
       " ['آن', 'زمان'],\n",
       " ['که', 'همه'],\n",
       " ['هفته', 'گذشته'],\n",
       " ['حدود', 'هزار'],\n",
       " ['عنوان', 'کرد'],\n",
       " ['اظهار', 'کرد'],\n",
       " ['عین', 'حال'],\n",
       " ['به', 'من'],\n",
       " ['شورای', 'نگهبان'],\n",
       " ['این', 'امر'],\n",
       " ['این', 'میان'],\n",
       " ['در', 'همان'],\n",
       " ['راه', 'و'],\n",
       " ['ادامه', 'دارد'],\n",
       " ['و', 'آمریکا'],\n",
       " ['رفت', 'و'],\n",
       " ['ریاست', 'جمهوری'],\n",
       " ['حاج', 'قاسم'],\n",
       " ['بازار', 'سرمایه'],\n",
       " ['افزود', 'در'],\n",
       " ['نشان', 'داد'],\n",
       " ['وزارت', 'خارجه'],\n",
       " ['این', 'سوال'],\n",
       " ['او', 'با'],\n",
       " ['کشور', 'از'],\n",
       " ['قرار', 'گیرد'],\n",
       " ['ما', 'با'],\n",
       " ['قانون', 'اساسی'],\n",
       " ['ورود', 'به'],\n",
       " ['به', 'شهادت'],\n",
       " ['این', 'منطقه'],\n",
       " ['دارند', 'که'],\n",
       " ['در', 'این\\u200cباره'],\n",
       " ['گفته', 'است'],\n",
       " ['از', 'درصد'],\n",
       " ['بخش', 'خصوصی'],\n",
       " ['هر', 'روز'],\n",
       " ['به', 'دولت'],\n",
       " ['به', 'همشهری'],\n",
       " ['شورای', 'عالی'],\n",
       " ['دیگری', 'از'],\n",
       " ['مدیریت', 'شهری'],\n",
       " ['دست', 'به'],\n",
       " ['در', 'آینده'],\n",
       " ['در', 'جهت'],\n",
       " ['انجام', 'شود'],\n",
       " ['اضافه', 'کرد'],\n",
       " ['به', 'خود'],\n",
       " ['قرار', 'دارند'],\n",
       " ['با', 'عنوان'],\n",
       " ['مورد', 'توجه'],\n",
       " ['و', 'کار'],\n",
       " ['که', 'ایران'],\n",
       " ['امنیت', 'ملی'],\n",
       " ['خودش', 'را'],\n",
       " ['تا', 'از'],\n",
       " ['از', 'دیگر'],\n",
       " ['رییس', 'سازمان'],\n",
       " ['این', 'حادثه'],\n",
       " ['به', 'منظور'],\n",
       " ['جایی', 'که'],\n",
       " ['سال', 'پیش'],\n",
       " ['کند', 'که'],\n",
       " ['برای', 'ما'],\n",
       " ['نفر', 'در'],\n",
       " ['داریم', 'که'],\n",
       " ['برگزار', 'می\\u200cشود'],\n",
       " ['سال', 'است'],\n",
       " ['آب', 'و'],\n",
       " ['در', 'قبال'],\n",
       " ['چند', 'سال'],\n",
       " ['سال', 'از'],\n",
       " ['به', 'برجام'],\n",
       " ['او', 'به'],\n",
       " ['به', 'کشور'],\n",
       " ['خود', 'و'],\n",
       " ['پیدا', 'کرده'],\n",
       " ['این', 'باره'],\n",
       " ['از', 'ابتدای'],\n",
       " ['به', 'سال'],\n",
       " ['افزایش', 'یافته'],\n",
       " ['می\\u200cدهد', 'و'],\n",
       " ['از', 'مهم\\u200cترین'],\n",
       " ['لازم', 'را'],\n",
       " ['دیگر', 'در'],\n",
       " ['شهردار', 'تهران'],\n",
       " ['این', 'مدت'],\n",
       " ['تا', 'با'],\n",
       " ['این', 'بیماری'],\n",
       " ['محسوب', 'می\\u200cشود'],\n",
       " ['این', 'اساس'],\n",
       " ['آقای', 'روحانی'],\n",
       " ['در', 'سراسر'],\n",
       " ['در', 'نشست'],\n",
       " ['شیوع', 'کرونا'],\n",
       " ['باشند', 'و'],\n",
       " ['از', 'همان'],\n",
       " ['به', 'نفع'],\n",
       " ['در', 'عرصه'],\n",
       " ['رسیدگی', 'به'],\n",
       " ['که', 'او'],\n",
       " ['کرد', 'تا'],\n",
       " ['شرایطی', 'که'],\n",
       " ['بعضی', 'از'],\n",
       " ['برای', 'مردم'],\n",
       " ['به', 'معنای'],\n",
       " ['دولت', 'به'],\n",
       " ['به', 'وجود'],\n",
       " ['کمک', 'به'],\n",
       " ['قرار', 'داده'],\n",
       " ['کرونا', 'و'],\n",
       " ['اگر', 'این'],\n",
       " ['در', 'بین'],\n",
       " ['کشور', 'با'],\n",
       " ['و', 'آن\\u200cها'],\n",
       " ['هم', 'برای'],\n",
       " ['از', 'دولت'],\n",
       " ['برای', 'تامین'],\n",
       " ['ارتباط', 'با'],\n",
       " ['وزیر', 'امور'],\n",
       " ['را', 'نشان'],\n",
       " ['کار', 'و'],\n",
       " ['و', 'بدون'],\n",
       " ['به', 'هیچ'],\n",
       " ['ما', 'هم'],\n",
       " ['خیلی', 'از'],\n",
       " ['که', 'می\\u200cتواند'],\n",
       " ['کشور', 'ما'],\n",
       " ['تبدیل', 'به'],\n",
       " ['در', 'وضعیت'],\n",
       " ['علی', 'ع'],\n",
       " ['این', 'خصوص'],\n",
       " ['این', 'مراسم'],\n",
       " ['سال', 'اخیر'],\n",
       " ['از', 'خود'],\n",
       " ['در', 'دنیا'],\n",
       " ['گزارش', 'فارس'],\n",
       " ['از', 'همین'],\n",
       " ['نیروهای', 'مسلح'],\n",
       " ['مردم', 'از'],\n",
       " ['مرتبط', 'با'],\n",
       " ['و', 'سپس'],\n",
       " ['قرار', 'می\\u200cگیرد'],\n",
       " ['مقام', 'معظم'],\n",
       " ['و', 'اجتماعی'],\n",
       " ['در', 'یکی'],\n",
       " ['موضوع', 'را'],\n",
       " ['عمومی', 'و'],\n",
       " ['مهم', 'است'],\n",
       " ['این', 'تیم'],\n",
       " ['از', 'ایران'],\n",
       " ['توافق', 'هسته\\u200cای'],\n",
       " ['تا', 'این'],\n",
       " ['در', 'مرحله'],\n",
       " ['در', 'چند'],\n",
       " ['با', 'افزایش'],\n",
       " ['کرده\\u200cاند', 'و'],\n",
       " ['و', 'توسعه'],\n",
       " ['ابتلا', 'به'],\n",
       " ['می\\u200cشوند', 'و'],\n",
       " ['باعث', 'شد'],\n",
       " ['و', 'میلیون'],\n",
       " ['درصد', 'افزایش'],\n",
       " ['معظم', 'رهبری'],\n",
       " ['خود', 'با'],\n",
       " ['وابسته', 'به'],\n",
       " ['تهران', 'به'],\n",
       " ['کنند', 'که'],\n",
       " ['تلاش', 'برای'],\n",
       " ['ستاد', 'ملی'],\n",
       " ['در', 'دو'],\n",
       " ['آغاز', 'شد'],\n",
       " ['خطاب', 'به'],\n",
       " ['بر', 'اثر'],\n",
       " ['به', 'افزایش'],\n",
       " ['و', 'تلاش'],\n",
       " ['افکار', 'عمومی'],\n",
       " ['سال\\u200cهای', 'گذشته'],\n",
       " ['به', 'کرونا'],\n",
       " ['که', 'برخی'],\n",
       " ['یک', 'روز'],\n",
       " ['که', 'یکی'],\n",
       " ['رابطه', 'با'],\n",
       " ['انجام', 'شد'],\n",
       " ['و', 'همین'],\n",
       " ['بازگشت', 'به'],\n",
       " ['از', 'زمان'],\n",
       " ['این', 'وضعیت'],\n",
       " ['فرهنگ', 'و'],\n",
       " ['را', 'داشته'],\n",
       " ['شورای', 'امنیت'],\n",
       " ['معتقد', 'است'],\n",
       " ['در', 'چنین'],\n",
       " ['حدود', 'درصد'],\n",
       " ['و', 'کاهش'],\n",
       " ['هر', 'چند'],\n",
       " ['وجود', 'داشته'],\n",
       " ['برای', 'مقابله'],\n",
       " ['فدراسیون', 'فوتبال'],\n",
       " ['به', 'خوبی'],\n",
       " ['میلیون', 'نفر'],\n",
       " ['ما', 'باید'],\n",
       " ['امام', 'حسین'],\n",
       " ['که', 'من'],\n",
       " ['از', 'انقلاب'],\n",
       " ['در', 'آستانه'],\n",
       " ['به', 'توافق'],\n",
       " ['این', 'همه'],\n",
       " ['دو', 'سال'],\n",
       " ['داخلی', 'و'],\n",
       " ['برای', 'اینکه'],\n",
       " ['شبکه\\u200cهای', 'اجتماعی'],\n",
       " ['را', 'باید'],\n",
       " ['خود', 'از'],\n",
       " ['این', 'شهر'],\n",
       " ['که', 'آن'],\n",
       " ['همه', 'این'],\n",
       " ['که', 'آمریکا'],\n",
       " ['مبتلا', 'به'],\n",
       " ['این', 'سازمان'],\n",
       " ['موجود', 'در'],\n",
       " ['شد', 'اما'],\n",
       " ['به', 'درصد'],\n",
       " ['شود', 'تا'],\n",
       " ['اجرای', 'این'],\n",
       " ['می\\u200cتواند', 'به'],\n",
       " ['که', 'حتی'],\n",
       " ['دیگر', 'به'],\n",
       " ['نیست', 'بلکه'],\n",
       " ['کنیم', 'که'],\n",
       " ['از', 'روز'],\n",
       " ['این', 'دوره'],\n",
       " ['اما', 'از'],\n",
       " ['تهران', 'با'],\n",
       " ['هستیم', 'که'],\n",
       " ['اگر', 'در'],\n",
       " ['که', 'خود'],\n",
       " ['در', 'حاشیه'],\n",
       " ['با', 'همکاری'],\n",
       " ['به', 'شمار'],\n",
       " ['آنجا', 'که'],\n",
       " ['در', 'عراق'],\n",
       " ['هسته\\u200cای', 'ایران'],\n",
       " ['را', 'دارند'],\n",
       " ['تا', 'سال'],\n",
       " ['نرخ', 'تورم'],\n",
       " ['این', 'استان'],\n",
       " ['اقتصاد', 'ایران'],\n",
       " ['و', 'شهرسازی'],\n",
       " ['مردم', 'ایران'],\n",
       " ['و', 'حالا'],\n",
       " ['واکنش', 'به'],\n",
       " ['ضمن', 'اینکه'],\n",
       " ['را', 'فراهم'],\n",
       " ['از', 'میلیون'],\n",
       " ['و', 'تنها'],\n",
       " ['از', 'محل'],\n",
       " ['شده\\u200cاند', 'و'],\n",
       " ['کالاهای', 'اساسی'],\n",
       " ['و', 'من'],\n",
       " ['روسیه', 'و'],\n",
       " ['اعلام', 'کردند'],\n",
       " ['نفت', 'و'],\n",
       " ['از', 'دو'],\n",
       " ['در', 'معرض'],\n",
       " ['گفته', 'می\\u200cشود'],\n",
       " ['که', 'چرا'],\n",
       " ['برنامه', 'و'],\n",
       " ['برجام', 'و'],\n",
       " ['این', 'بخش'],\n",
       " ['این', 'مسیر'],\n",
       " ['این', 'نکته'],\n",
       " ['وی', 'گفت'],\n",
       " ['واکسن', 'کرونا'],\n",
       " ['برای', 'حل'],\n",
       " ['این', 'رژیم'],\n",
       " ['لیگ', 'برتر'],\n",
       " ['نمایندگان', 'مجلس'],\n",
       " ['خبرگزاری', 'فارس'],\n",
       " ['بر', 'آن'],\n",
       " ['انقلاب', 'و'],\n",
       " ['در', 'ارتباط'],\n",
       " ['در', 'خانه'],\n",
       " ['دیروز', 'در'],\n",
       " ['این', 'قانون'],\n",
       " ['کاخ', 'سفید'],\n",
       " ['هستیم', 'و'],\n",
       " ['این', 'گروه'],\n",
       " ['و', 'ایران'],\n",
       " ['میلیون', 'دلار'],\n",
       " ['جان', 'خود'],\n",
       " ['حسین', 'ع'],\n",
       " ['در', 'گزارشی'],\n",
       " ['متعلق', 'به']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [[word2vec_model.wv.index_to_key[x[0][0]], word2vec_model.wv.index_to_key[x[0][1]]] for x in sorted(biword_counts.items(), key = lambda x: x[1], reverse=True)[300:800]]\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9ea3c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['مورد', 'بررسی', 'قرار'],\n",
       " ['و', 'از', 'آن'],\n",
       " ['کرونا', 'در', 'کشور'],\n",
       " ['در', 'خارج', 'از'],\n",
       " ['مبتلا', 'به', 'کووید'],\n",
       " ['در', 'این', 'صورت'],\n",
       " ['که', 'منجر', 'به'],\n",
       " ['ماه', 'مبارک', 'رمضان'],\n",
       " ['شد', 'و', 'به'],\n",
       " ['هر', 'یک', 'از'],\n",
       " ['در', 'این', 'بین'],\n",
       " ['برگزار', 'خواهد', 'شد'],\n",
       " ['بعد', 'از', 'این'],\n",
       " ['رعایت', 'پروتکل\\u200cهای', 'بهداشتی'],\n",
       " ['در', 'شرایط', 'فعلی'],\n",
       " ['داشته', 'باشند', 'و'],\n",
       " ['است', 'که', 'دولت'],\n",
       " ['در', 'روزهای', 'اخیر'],\n",
       " ['پس', 'از', 'این'],\n",
       " ['صنعت', 'معدن', 'و'],\n",
       " ['حال', 'انجام', 'است'],\n",
       " ['کسب', 'و', 'کار'],\n",
       " ['در', 'شهر', 'تهران'],\n",
       " ['دولت', 'تدبیر', 'و'],\n",
       " ['و', 'این', 'موضوع'],\n",
       " ['ورزش', 'و', 'جوانان'],\n",
       " ['معدن', 'و', 'تجارت'],\n",
       " ['گفت\\u200cوگو', 'با', 'خبرگزاری'],\n",
       " ['در', 'همین', 'زمینه'],\n",
       " ['مجمع', 'تشخیص', 'مصلحت'],\n",
       " ['پاسخ', 'به', 'سوالی'],\n",
       " ['داخلی', 'و', 'خارجی'],\n",
       " ['است', 'و', 'اگر'],\n",
       " ['در', 'سال', 'در'],\n",
       " ['به', 'هیچ', 'عنوان'],\n",
       " ['با', 'این', 'وجود'],\n",
       " ['مردم', 'را', 'به'],\n",
       " ['و', 'در', 'حال'],\n",
       " ['که', 'برخی', 'از'],\n",
       " ['انقلاب', 'اسلامی', 'و'],\n",
       " ['یکی', 'از', 'آن\\u200cها'],\n",
       " ['کرد', 'و', 'به'],\n",
       " ['و', 'میلیارد', 'تومان'],\n",
       " ['خروج', 'آمریکا', 'از'],\n",
       " ['کسانی', 'که', 'در'],\n",
       " ['در', 'کشور', 'به'],\n",
       " ['در', 'نظر', 'گرفته'],\n",
       " ['تا', 'هزار', 'تومان'],\n",
       " ['در', 'طول', 'این'],\n",
       " ['در', 'مواجهه', 'با'],\n",
       " ['به', 'این', 'معنا'],\n",
       " ['سرویس', 'سیاسی', '-'],\n",
       " ['با', 'وجود', 'اینکه'],\n",
       " ['و', 'در', 'عین'],\n",
       " ['به', 'هیچ', 'وجه'],\n",
       " ['بیش', 'از', 'هر'],\n",
       " ['را', 'نسبت', 'به'],\n",
       " ['شد', 'که', 'در'],\n",
       " ['را', 'در', 'دستور'],\n",
       " ['غذا', 'و', 'دارو'],\n",
       " ['آمریکا', 'از', 'برجام'],\n",
       " ['به', 'کووید', 'در'],\n",
       " ['است', 'چرا', 'که'],\n",
       " ['از', 'این', 'طریق'],\n",
       " ['باشگاه', 'خبرنگاران', 'جوان'],\n",
       " ['در', 'شبکه\\u200cهای', 'اجتماعی'],\n",
       " ['تشخیص', 'مصلحت', 'نظام'],\n",
       " ['در', 'نشست', 'خبری'],\n",
       " ['برای', 'کمک', 'به'],\n",
       " ['به\\u200cعنوان', 'یکی', 'از'],\n",
       " ['برخی', 'از', 'این'],\n",
       " ['در', 'مصاحبه', 'با'],\n",
       " ['و', 'جلوگیری', 'از'],\n",
       " ['را', 'به', 'صورت'],\n",
       " ['به', 'ویژه', 'در'],\n",
       " ['بوده', 'است', 'که'],\n",
       " ['نفت', 'و', 'گاز'],\n",
       " ['آمریکا', 'و', 'اروپا'],\n",
       " ['رییس', 'قوه', 'قضاییه'],\n",
       " ['مرگ', 'و', 'میر'],\n",
       " ['را', 'از', 'طریق'],\n",
       " ['مبارزه', 'با', 'فساد'],\n",
       " ['کاهش', 'یافته', 'است'],\n",
       " ['برای', 'نخستین', 'بار'],\n",
       " ['شورای', 'اسلامی', 'در'],\n",
       " ['اجرای', 'این', 'طرح'],\n",
       " ['روی', 'کار', 'آمدن'],\n",
       " ['به', 'گزارش', 'پایگاه'],\n",
       " ['وزیر', 'راه', 'و'],\n",
       " ['که', 'این', 'روزها'],\n",
       " ['تعداد', 'زیادی', 'از'],\n",
       " ['امام', 'صادق', 'ع'],\n",
       " ['و', 'نسبت', 'به'],\n",
       " ['چند', 'روز', 'پیش'],\n",
       " ['که', 'بر', 'اساس'],\n",
       " ['بر', 'اساس', 'گزارش'],\n",
       " ['می\\u200cشود', 'و', 'در'],\n",
       " ['کار', 'را', 'انجام'],\n",
       " ['نظام', 'جمهوری', 'اسلامی'],\n",
       " ['اعلام', 'کرده', 'که'],\n",
       " ['سال', 'گذشته', 'در'],\n",
       " ['سازمان', 'ملل', 'متحد'],\n",
       " ['و', 'هم', 'در'],\n",
       " ['و', 'در', 'سال'],\n",
       " ['اعلام', 'کردند', 'که'],\n",
       " ['در', 'این', 'بخش'],\n",
       " ['و', 'در', 'صورت'],\n",
       " ['در', 'شرایط', 'کنونی'],\n",
       " ['در', 'سال', 'و'],\n",
       " ['کرده', 'و', 'از'],\n",
       " ['در', 'ادامه', 'با'],\n",
       " ['را', 'به', 'خود'],\n",
       " ['در', 'این', 'طرح'],\n",
       " ['تا', 'پیش', 'از'],\n",
       " ['که', 'این', 'موضوع'],\n",
       " ['و', 'با', 'این'],\n",
       " ['هستند', 'که', 'در'],\n",
       " ['در', 'این', 'گزارش'],\n",
       " ['به', 'گزارش', 'ایرنا'],\n",
       " ['طبیعی', 'است', 'که'],\n",
       " ['گفت', 'در', 'این'],\n",
       " ['و', 'هزار', 'نفر'],\n",
       " ['و', 'او', 'را'],\n",
       " ['که', 'به', 'این'],\n",
       " ['سرمربی', 'تیم', 'ملی'],\n",
       " ['ممکن', 'است', 'در'],\n",
       " ['نسبت', 'به', 'این'],\n",
       " ['وزارت', 'جهاد', 'کشاورزی'],\n",
       " ['در', 'سال', 'آینده'],\n",
       " ['ایران', 'در', 'این'],\n",
       " ['که', 'در', 'صورت'],\n",
       " ['روز', 'گذشته', 'در'],\n",
       " ['ما', 'در', 'این'],\n",
       " ['وی', 'اضافه', 'کرد'],\n",
       " ['توجه', 'به', 'شرایط'],\n",
       " ['وزارت', 'آموزش', 'و'],\n",
       " ['ایران', 'و', 'آمریکا'],\n",
       " ['دارد', 'و', 'در'],\n",
       " ['وی', 'خاطرنشان', 'کرد'],\n",
       " ['وی', 'افزود', 'در'],\n",
       " ['از', 'دست', 'داد'],\n",
       " ['ابتلا', 'به', 'کرونا'],\n",
       " ['در', 'جمع', 'خبرنگاران'],\n",
       " ['در', 'مقابله', 'با'],\n",
       " ['همچنان', 'ادامه', 'دارد'],\n",
       " ['بانک', 'مرکزی', 'در'],\n",
       " ['از', 'سوی', 'دولت'],\n",
       " ['شهید', 'مدافع', 'حرم'],\n",
       " ['حل', 'و', 'فصل'],\n",
       " ['ما', 'را', 'به'],\n",
       " ['به', 'ویروس', 'کرونا'],\n",
       " ['نفر', 'از', 'بیماران'],\n",
       " ['به', 'پایان', 'رسید'],\n",
       " ['برای', 'حمایت', 'از'],\n",
       " ['به', 'گفته', 'وی'],\n",
       " ['از', 'دست', 'داده\\u200cاند'],\n",
       " ['در', 'این', 'سال\\u200cها'],\n",
       " ['با', 'رژیم', 'صهیونیستی'],\n",
       " ['را', 'هم', 'به'],\n",
       " ['شهر', 'تهران', 'در'],\n",
       " ['و', 'این', 'در'],\n",
       " ['و', 'در', 'مقابل'],\n",
       " ['دولت', 'و', 'مجلس'],\n",
       " ['را', 'از', 'بین'],\n",
       " ['بیش', 'از', 'میلیارد'],\n",
       " ['را', 'به', 'همراه'],\n",
       " ['است', 'اما', 'در'],\n",
       " ['بیماران', 'مبتلا', 'به'],\n",
       " ['این', 'موضوع', 'در'],\n",
       " ['وی', 'با', 'تاکید'],\n",
       " ['در', 'دیدار', 'با'],\n",
       " ['در', 'حمایت', 'از'],\n",
       " ['به', 'این', 'دلیل'],\n",
       " ['و', 'حمایت', 'از'],\n",
       " ['رخ', 'داده', 'است'],\n",
       " ['پیدا', 'کرده', 'و'],\n",
       " ['صندوق', 'توسعه', 'ملی'],\n",
       " ['را', 'از', 'این'],\n",
       " ['فرهنگ', 'و', 'ارشاد'],\n",
       " ['دارد', 'که', 'در'],\n",
       " ['باید', 'به', 'این'],\n",
       " ['را', 'بر', 'عهده'],\n",
       " ['و', 'در', 'آن'],\n",
       " ['در', 'طول', 'سال'],\n",
       " ['سازمان', 'غذا', 'و'],\n",
       " ['که', 'ما', 'در'],\n",
       " ['است', 'که', 'می\\u200cتواند'],\n",
       " ['کودکان', 'و', 'نوجوانان'],\n",
       " ['کرد', 'که', 'این'],\n",
       " ['و', 'نفر', 'رسید'],\n",
       " ['پیروزی', 'انقلاب', 'اسلامی'],\n",
       " ['که', 'بخشی', 'از'],\n",
       " ['برخی', 'از', 'آن\\u200cها'],\n",
       " ['به', 'عنوان', 'مثال'],\n",
       " ['کرد', 'و', 'افزود'],\n",
       " ['را', 'داشته', 'باشد'],\n",
       " ['قرار', 'است', 'در'],\n",
       " ['تیم', 'ملی', 'فوتبال'],\n",
       " ['فضای', 'مجازی', 'و'],\n",
       " ['که', 'از', 'آن'],\n",
       " ['که', 'به', 'دلیل'],\n",
       " ['درحالی', 'است', 'که'],\n",
       " ['تا', 'قبل', 'از'],\n",
       " ['است', 'که', 'هر'],\n",
       " ['که', 'با', 'وجود'],\n",
       " ['هزار', 'و', 'واحد'],\n",
       " ['استفاده', 'از', 'این'],\n",
       " ['سخنگوی', 'وزارت', 'خارجه'],\n",
       " ['از', 'آن', 'در'],\n",
       " ['معاون', 'اول', 'رییس\\u200cجمهور'],\n",
       " ['که', 'با', 'این'],\n",
       " ['بیش', 'از', 'سال'],\n",
       " ['سید', 'ابراهیم', 'رییسی'],\n",
       " ['ادامه', 'خواهد', 'داشت'],\n",
       " ['سازمان', 'امور', 'مالیاتی'],\n",
       " ['در', 'همین', 'حال'],\n",
       " ['به', 'این', 'نکته'],\n",
       " ['از', 'این', 'تعداد'],\n",
       " ['نفر', 'از', 'آن\\u200cها'],\n",
       " ['کرده', 'و', 'با'],\n",
       " ['باعث', 'شد', 'تا'],\n",
       " ['امام', 'رضا', 'ع'],\n",
       " ['پس', 'از', 'سال'],\n",
       " ['را', 'در', 'پیش'],\n",
       " ['از', 'دست', 'داده'],\n",
       " ['معظم', 'انقلاب', 'اسلامی'],\n",
       " ['برای', 'اولین', 'بار'],\n",
       " ['از', 'هزار', 'نفر'],\n",
       " ['و', 'ارشاد', 'اسلامی'],\n",
       " ['از', 'سال', 'تا'],\n",
       " ['در', 'ادامه', 'به'],\n",
       " ['که', 'در', 'سال\\u200cهای'],\n",
       " ['به', 'گزارش', 'تسنیم'],\n",
       " ['و', 'برخی', 'از'],\n",
       " ['بعد', 'از', 'سال'],\n",
       " ['کمیته', 'ملی', 'المپیک'],\n",
       " ['معتقد', 'است', 'که'],\n",
       " ['آن\\u200cها', 'را', 'در'],\n",
       " ['از', 'همین', 'رو'],\n",
       " ['دانست', 'و', 'گفت'],\n",
       " ['است', 'و', 'ما'],\n",
       " ['به', 'اینکه', 'در'],\n",
       " ['به', 'عنوان', 'یکی'],\n",
       " ['و', 'حتی', 'در'],\n",
       " ['بین', 'ایران', 'و'],\n",
       " ['هر', 'چند', 'که'],\n",
       " ['یکی', 'از', 'دلایل'],\n",
       " ['برنامه', 'هسته\\u200cای', 'ایران'],\n",
       " ['استفاده', 'از', 'ماسک'],\n",
       " ['بانک', 'مرکزی', 'و'],\n",
       " ['و', 'در', 'واقع'],\n",
       " ['کشور', 'را', 'در'],\n",
       " ['وی', 'اظهار', 'داشت'],\n",
       " ['عنوان', 'یکی', 'از'],\n",
       " ['چهارمحال', 'و', 'بختیاری'],\n",
       " ['ایران', 'را', 'در'],\n",
       " ['با', 'نتیجه', 'بر'],\n",
       " ['در', 'یک', 'سال'],\n",
       " ['توجه', 'به', 'این'],\n",
       " ['تا', 'به', 'امروز'],\n",
       " ['از', 'بانک', 'مرکزی'],\n",
       " ['به', 'این', 'کشور'],\n",
       " ['طی', 'سال', 'گذشته'],\n",
       " ['به', 'استفاده', 'از'],\n",
       " ['در', 'این', 'استان'],\n",
       " ['و', 'در', 'کنار'],\n",
       " ['میلیارد', 'تومان', 'از'],\n",
       " ['ایجاد', 'کرده', 'است'],\n",
       " ['مهم', 'این', 'است'],\n",
       " ['بیش', 'از', 'حد'],\n",
       " ['خبرگزاری', 'صدا', 'و'],\n",
       " ['و', 'چه', 'در'],\n",
       " ['به', 'گفته', 'او'],\n",
       " ['حاکی', 'از', 'آن'],\n",
       " ['مبارزه', 'با', 'کرونا'],\n",
       " ['اما', 'در', 'این'],\n",
       " ['کند', 'و', 'به'],\n",
       " ['در', 'همین', 'رابطه'],\n",
       " ['تصریح', 'کرد', 'در'],\n",
       " ['و', 'رژیم', 'صهیونیستی'],\n",
       " ['داده', 'است', 'که'],\n",
       " ['کسی', 'است', 'که'],\n",
       " ['مورد', 'استفاده', 'قرار'],\n",
       " ['انجام', 'داده', 'است'],\n",
       " ['با', 'این', 'همه'],\n",
       " ['برای', 'دفاع', 'از'],\n",
       " ['است', 'در', 'این'],\n",
       " ['به', 'این', 'مسیله'],\n",
       " ['با', 'انتقاد', 'از'],\n",
       " ['خواهد', 'کرد', 'و'],\n",
       " ['به', 'عبارت', 'دیگر'],\n",
       " ['چیزی', 'است', 'که'],\n",
       " ['از', 'ابتدای', 'سال'],\n",
       " ['طی', 'سال\\u200cهای', 'اخیر'],\n",
       " ['وی', 'در', 'پاسخ'],\n",
       " ['به', 'میلیون', 'و'],\n",
       " ['لیگ', 'قهرمانان', 'آسیا'],\n",
       " ['و', 'در', 'ادامه'],\n",
       " ['در', 'روزهای', 'گذشته'],\n",
       " ['در', 'حوزه\\u200cهای', 'مختلف'],\n",
       " ['باید', 'توجه', 'داشت'],\n",
       " ['را', 'در', 'دست'],\n",
       " ['را', 'هم', 'در'],\n",
       " ['را', 'انجام', 'دهد'],\n",
       " ['می\\u200cکند', 'و', 'می\\u200cگوید'],\n",
       " ['گزارش', 'باشگاه', 'خبرنگاران'],\n",
       " ['شد', 'و', 'با'],\n",
       " ['بخش', 'زیادی', 'از'],\n",
       " ['و', 'گفت', 'که'],\n",
       " ['به', 'این', 'پرسش'],\n",
       " ['کار', 'خود', 'را'],\n",
       " ['قرار', 'داده', 'و'],\n",
       " ['این', 'درحالی', 'است'],\n",
       " ['که', 'در', 'یک'],\n",
       " ['از', 'یک', 'سو'],\n",
       " ['کرد', 'و', 'با'],\n",
       " ['کرد', 'و', 'از'],\n",
       " ['بوده', 'و', 'در'],\n",
       " ['که', 'باید', 'در'],\n",
       " ['خواهد', 'شد', 'که'],\n",
       " ['از', 'حضور', 'در'],\n",
       " ['به', 'گزارش', 'باشگاه'],\n",
       " ['است', 'که', 'یک'],\n",
       " ['هزار', 'نفر', 'از'],\n",
       " ['شورای', 'اسلامی', 'شهر'],\n",
       " ['فرهنگی', 'و', 'اجتماعی'],\n",
       " ['که', 'خود', 'را'],\n",
       " ['روسیه', 'و', 'چین'],\n",
       " ['گفت', 'با', 'توجه'],\n",
       " ['پدر', 'و', 'مادر'],\n",
       " ['که', 'باید', 'به'],\n",
       " ['شود', 'و', 'در'],\n",
       " ['این', 'معنا', 'که'],\n",
       " ['خود', 'را', 'بر'],\n",
       " ['قبل', 'از', 'آن'],\n",
       " ['از', 'پیروزی', 'انقلاب'],\n",
       " ['با', 'تکیه', 'بر'],\n",
       " ['که', 'در', 'نهایت'],\n",
       " ['ارزش', 'پول', 'ملی'],\n",
       " ['ستاد', 'اجرایی', 'فرمان'],\n",
       " ['در', 'این', 'راه'],\n",
       " ['چین', 'و', 'روسیه'],\n",
       " ['بسیار', 'مهم', 'است'],\n",
       " ['نظر', 'می\\u200cرسد', 'که'],\n",
       " ['برای', 'حل', 'مشکلات'],\n",
       " ['افرادی', 'که', 'در'],\n",
       " ['به', 'گزارش', 'وبدا'],\n",
       " ['که', 'آن', 'را'],\n",
       " ['شهرداری', 'تهران', 'در'],\n",
       " ['از', 'این', 'دست'],\n",
       " ['او', 'با', 'بیان'],\n",
       " ['در', 'سال', 'با'],\n",
       " ['و', 'کسانی', 'که'],\n",
       " ['می\\u200cشود', 'که', 'در'],\n",
       " ['اصل', 'قانون', 'اساسی'],\n",
       " ['پس', 'از', 'پایان'],\n",
       " ['است', 'و', 'نه'],\n",
       " ['این', 'مسیله', 'را'],\n",
       " ['روز', 'پس', 'از'],\n",
       " ['رژیم', 'صهیونیستی', 'و'],\n",
       " ['اعضای', 'شورای', 'شهر'],\n",
       " ['اسلامی', 'ایران', 'و'],\n",
       " ['به', 'ازای', 'هر'],\n",
       " ['که', 'در', 'طول'],\n",
       " ['کند', 'و', 'در'],\n",
       " ['و', 'مقابله', 'با'],\n",
       " ['را', 'دارد', 'و'],\n",
       " ['وی', 'بیان', 'کرد'],\n",
       " ['ارتش', 'جمهوری', 'اسلامی'],\n",
       " ['یک', 'هزار', 'و'],\n",
       " ['که', 'از', 'سال'],\n",
       " ['افزایش', 'یافته', 'و'],\n",
       " ['و', 'با', 'وجود'],\n",
       " ['بسیاری', 'از', 'مردم'],\n",
       " ['گفته', 'است', 'که'],\n",
       " ['آغاز', 'شد', 'و'],\n",
       " ['که', 'نشان', 'می\\u200cدهد'],\n",
       " ['و', 'رفاه', 'اجتماعی'],\n",
       " ['با', 'استناد', 'به'],\n",
       " ['برای', 'این', 'کار'],\n",
       " ['در', 'این', 'مرحله'],\n",
       " ['پس', 'از', 'انقلاب'],\n",
       " ['برگزار', 'شد', 'و'],\n",
       " ['لازم', 'به', 'ذکر'],\n",
       " ['که', 'از', 'طریق'],\n",
       " ['به', 'ذکر', 'است'],\n",
       " ['از', 'آنجایی', 'که'],\n",
       " ['شهردار', 'تهران', 'در'],\n",
       " ['در', 'ماه\\u200cهای', 'اخیر'],\n",
       " ['تلاش', 'خود', 'را'],\n",
       " ['در', 'این', 'حادثه'],\n",
       " ['هزار', 'تومان', 'است'],\n",
       " ['در', 'حال', 'بررسی'],\n",
       " ['به', 'آن', 'اشاره'],\n",
       " ['قوه', 'قضاییه', 'در'],\n",
       " ['بازگشت', 'به', 'برجام'],\n",
       " ['را', 'در', 'نظر'],\n",
       " ['عنوان', 'کرد', 'و'],\n",
       " ['شورای', 'امنیت', 'سازمان'],\n",
       " ['شد', 'و', 'این'],\n",
       " ['سال', 'گذشته', 'به'],\n",
       " ['او', 'ادامه', 'داد'],\n",
       " ['از', 'دست', 'دادن'],\n",
       " ['را', 'داشته', 'باشند'],\n",
       " ['امنیت', 'سازمان', 'ملل'],\n",
       " ['شد', 'که', 'این'],\n",
       " ['و', 'از', 'طریق'],\n",
       " ['ادامه', 'دارد', 'و'],\n",
       " ['این', 'کشور', 'از'],\n",
       " ['درست', 'است', 'که'],\n",
       " ['که', 'به', 'صورت'],\n",
       " ['این', 'را', 'هم'],\n",
       " ['است', 'که', 'مردم'],\n",
       " ['گرفته', 'است', 'و'],\n",
       " ['می\\u200cتوان', 'گفت', 'که'],\n",
       " ['تا', 'به', 'حال'],\n",
       " ['در', 'دفاع', 'از'],\n",
       " ['را', 'نیز', 'به'],\n",
       " ['و', 'در', 'یک'],\n",
       " ['رژیم', 'صهیونیستی', 'به'],\n",
       " ['و', 'تاکید', 'کرد'],\n",
       " ['ایران', 'در', 'سال'],\n",
       " ['در', 'سراسر', 'جهان'],\n",
       " ['وزارت', 'ورزش', 'و'],\n",
       " ['را', 'در', 'پی'],\n",
       " ['و', 'خود', 'را'],\n",
       " ['جمهوری', 'اسلامی', 'در'],\n",
       " ['در', 'ایران', 'و'],\n",
       " ['در', 'غیر', 'این'],\n",
       " ['توجه', 'داشت', 'که'],\n",
       " ['کار', 'و', 'رفاه'],\n",
       " ['و', 'میلیون', 'دلار'],\n",
       " ['در', 'دولت', 'روحانی'],\n",
       " ['به', 'همشهری', 'گفت'],\n",
       " ['است', 'و', 'برای'],\n",
       " ['حدود', 'هزار', 'میلیارد'],\n",
       " ['پس', 'از', 'گذشت'],\n",
       " ['بخش', 'قابل\\u200cتوجهی', 'از'],\n",
       " ['است', 'که', 'همه'],\n",
       " ['که', 'به', 'گفته'],\n",
       " ['هر', 'کدام', 'از'],\n",
       " ['غیر', 'این', 'صورت'],\n",
       " ['او', 'را', 'در'],\n",
       " ['شهید', 'حاج', 'قاسم'],\n",
       " ['بخشی', 'از', 'آن'],\n",
       " ['و', 'گفت', 'در'],\n",
       " ['در', 'این', 'سال'],\n",
       " ['و', 'ممکن', 'است'],\n",
       " ['در', 'سازمان', 'ملل'],\n",
       " ['اما', 'پس', 'از'],\n",
       " ['را', 'پشت', 'سر'],\n",
       " ['وزارت', 'خارجه', 'آمریکا'],\n",
       " ['در', 'کنار', 'هم'],\n",
       " ['در', 'این', 'بیانیه'],\n",
       " ['سرویس', 'ورزشی', '-'],\n",
       " ['آن', 'را', 'از'],\n",
       " ['آمده', 'است', 'که'],\n",
       " ['و', 'بخشی', 'از'],\n",
       " ['هزار', 'نفر', 'در'],\n",
       " ['برای', 'شرکت', 'در'],\n",
       " ['این', 'موضوع', 'به'],\n",
       " ['تولید', 'ناخالص', 'داخلی'],\n",
       " ['انجام', 'خواهد', 'شد'],\n",
       " ['قرار', 'خواهد', 'گرفت'],\n",
       " ['گزارش', 'پایگاه', 'اطلاع\\u200cرسانی'],\n",
       " ['و', 'هزار', 'تن'],\n",
       " ['اعلام', 'کرد', 'و'],\n",
       " ['انجام', 'می\\u200cشود', 'و'],\n",
       " ['و', 'به', 'جای'],\n",
       " ['بیش', 'از', 'دو'],\n",
       " ['مشابه', 'سال', 'قبل'],\n",
       " ['از', 'هزار', 'میلیارد'],\n",
       " ['که', 'از', 'نظر'],\n",
       " ['ممکن', 'است', 'به'],\n",
       " ['قرار', 'داد', 'و'],\n",
       " ['ستاد', 'مقابله', 'با'],\n",
       " ['پس', 'از', 'آنکه'],\n",
       " ['میان', 'ایران', 'و'],\n",
       " ['در', 'ادامه', 'گفت'],\n",
       " ['گزارش', 'خبرگزاری', 'صدا'],\n",
       " ['را', 'بیش', 'از'],\n",
       " ['دوران', 'دفاع', 'مقدس'],\n",
       " ['را', 'اعلام', 'کرد'],\n",
       " ['به', 'نظر', 'من'],\n",
       " ['مدعی', 'شد', 'که'],\n",
       " ['کشور', 'وجود', 'دارد'],\n",
       " ['پیدا', 'کند', 'و'],\n",
       " ['در', 'این', 'شهر'],\n",
       " ['مدت', 'مشابه', 'سال'],\n",
       " ['به', 'دور', 'از'],\n",
       " ['بعد', 'از', 'انقلاب'],\n",
       " ['داشته', 'باشد', 'که'],\n",
       " ['پیش', 'از', 'آن'],\n",
       " ['را', 'که', 'به'],\n",
       " ['اجتماعی', 'و', 'فرهنگی'],\n",
       " ['تعاون', 'کار', 'و'],\n",
       " ['دو', 'هزار', 'و'],\n",
       " ['بدون', 'توجه', 'به'],\n",
       " ['درصد', 'افزایش', 'یافته'],\n",
       " ['ایران', 'و', 'عراق']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [[word2vec_model.wv.index_to_key[x[0][0]], word2vec_model.wv.index_to_key[x[0][1]], word2vec_model.wv.index_to_key[x[0][2]]] \n",
    "              for x in sorted(threeword_counts.items(), key = lambda x: x[1], reverse=True)[300:800]]\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "745c8548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['مبتلا', 'به', 'کووید', 'در'],\n",
       " ['را', 'در', 'دستور', 'کار'],\n",
       " ['و', 'در', 'عین', 'حال'],\n",
       " ['که', 'پیش', 'از', 'این'],\n",
       " ['وزارت', 'راه', 'و', 'شهرسازی'],\n",
       " ['مجلس', 'شورای', 'اسلامی', 'در'],\n",
       " ['وزارت', 'آموزش', 'و', 'پرورش'],\n",
       " ['با', 'توجه', 'به', 'شرایط'],\n",
       " ['است', 'که', 'در', 'این'],\n",
       " ['هزار', 'و', 'میلیارد', 'تومان'],\n",
       " ['هزار', 'و', 'نفر', 'رسید'],\n",
       " ['وی', 'با', 'تاکید', 'بر'],\n",
       " ['فرهنگ', 'و', 'ارشاد', 'اسلامی'],\n",
       " ['و', 'نفر', 'از', 'بیماران'],\n",
       " ['این', 'کار', 'را', 'انجام'],\n",
       " ['رهبر', 'معظم', 'انقلاب', 'اسلامی'],\n",
       " ['این', 'است', 'که', 'این'],\n",
       " ['به', 'عنوان', 'یکی', 'از'],\n",
       " ['خبرگزاری', 'صدا', 'و', 'سیما'],\n",
       " ['سازمان', 'غذا', 'و', 'دارو'],\n",
       " ['حاکی', 'از', 'آن', 'است'],\n",
       " ['میلیون', 'و', 'هزار', 'نفر'],\n",
       " ['خروج', 'آمریکا', 'از', 'برجام'],\n",
       " ['مهم', 'این', 'است', 'که'],\n",
       " ['این', 'درحالی', 'است', 'که'],\n",
       " ['و', 'بعد', 'از', 'آن'],\n",
       " ['به', 'گزارش', 'باشگاه', 'خبرنگاران'],\n",
       " ['را', 'از', 'دست', 'داده\\u200cاند'],\n",
       " ['گفت', 'با', 'توجه', 'به'],\n",
       " ['را', 'از', 'دست', 'داد'],\n",
       " ['وزیر', 'راه', 'و', 'شهرسازی'],\n",
       " ['به', 'نظر', 'می\\u200cرسد', 'که'],\n",
       " ['به', 'این', 'معنا', 'که'],\n",
       " ['وی', 'در', 'پاسخ', 'به'],\n",
       " ['به', 'میلیون', 'و', 'هزار'],\n",
       " ['لازم', 'به', 'ذکر', 'است'],\n",
       " ['او', 'با', 'بیان', 'اینکه'],\n",
       " ['به', 'هزار', 'و', 'نفر'],\n",
       " ['شورای', 'امنیت', 'سازمان', 'ملل'],\n",
       " ['گزارش', 'باشگاه', 'خبرنگاران', 'جوان'],\n",
       " ['در', 'غیر', 'این', 'صورت'],\n",
       " ['بیش', 'از', 'هزار', 'نفر'],\n",
       " ['جمهوری', 'اسلامی', 'ایران', 'و'],\n",
       " ['و', 'این', 'در', 'حالی'],\n",
       " ['به', 'گزارش', 'خبرگزاری', 'صدا'],\n",
       " ['کار', 'و', 'رفاه', 'اجتماعی'],\n",
       " ['را', 'از', 'دست', 'داده'],\n",
       " ['تعاون', 'کار', 'و', 'رفاه'],\n",
       " ['شهید', 'حاج', 'قاسم', 'سلیمانی'],\n",
       " ['گزارش', 'خبرگزاری', 'صدا', 'و'],\n",
       " ['او', 'با', 'اشاره', 'به'],\n",
       " ['پاسخ', 'به', 'این', 'پرسش'],\n",
       " ['حالی', 'است', 'که', 'در'],\n",
       " ['صحیفه', 'امام', 'ج', 'ص'],\n",
       " ['به', 'گزارش', 'پایگاه', 'اطلاع\\u200cرسانی'],\n",
       " ['میلیارد', 'و', 'میلیون', 'دلار'],\n",
       " ['از', 'دست', 'دادند', 'و'],\n",
       " ['این', 'است', 'که', 'ما'],\n",
       " ['با', 'بیان', 'اینکه', 'این'],\n",
       " ['باید', 'توجه', 'داشت', 'که'],\n",
       " ['این', 'است', 'که', 'با'],\n",
       " ['ارتش', 'جمهوری', 'اسلامی', 'ایران'],\n",
       " ['رییس', 'مجلس', 'شورای', 'اسلامی'],\n",
       " ['ستاد', 'اجرایی', 'فرمان', 'امام'],\n",
       " ['حدود', 'هزار', 'میلیارد', 'تومان'],\n",
       " ['وی', 'ادامه', 'داد', 'در'],\n",
       " ['در', 'خارج', 'از', 'کشور'],\n",
       " ['رهبر', 'معظم', 'انقلاب', 'در'],\n",
       " ['شورای', 'اسلامی', 'شهر', 'تهران'],\n",
       " ['نسبت', 'به', 'سال', 'گذشته'],\n",
       " ['پیش', 'از', 'این', 'نیز'],\n",
       " ['شورای', 'عالی', 'امنیت', 'ملی'],\n",
       " ['میلیون', 'و', 'هزار', 'تن'],\n",
       " ['کرد', 'با', 'توجه', 'به'],\n",
       " ['با', 'توجه', 'به', 'این'],\n",
       " ['هزار', 'و', 'نفر', 'دز'],\n",
       " ['دست', 'و', 'پنجه', 'نرم'],\n",
       " ['به', 'کووید', 'در', 'کشور'],\n",
       " ['که', 'در', 'حال', 'حاضر'],\n",
       " ['وزارت', 'ورزش', 'و', 'جوانان'],\n",
       " ['پاسخ', 'به', 'سوالی', 'درباره'],\n",
       " ['سخنگوی', 'وزارت', 'امور', 'خارجه'],\n",
       " ['در', 'واکنش', 'به', 'این'],\n",
       " ['بهداشت', 'درمان', 'و', 'آموزش'],\n",
       " ['در', 'پاسخ', 'به', 'سوال'],\n",
       " ['درمان', 'و', 'آموزش', 'پزشکی'],\n",
       " ['بر', 'این', 'است', 'که'],\n",
       " ['بیماران', 'مبتلا', 'به', 'کووید'],\n",
       " ['از', 'هزار', 'میلیارد', 'تومان'],\n",
       " ['به', 'این', 'پرسش', 'که'],\n",
       " ['از', 'بیماران', 'مبتلا', 'به'],\n",
       " ['در', 'شرایطی', 'است', 'که'],\n",
       " ['این', 'است', 'که', 'به'],\n",
       " ['بر', 'این', 'باورند', 'که'],\n",
       " ['اما', 'با', 'توجه', 'به'],\n",
       " ['بیمار', 'جدید', 'مبتلا', 'به'],\n",
       " ['پیش', 'از', 'این', 'در'],\n",
       " ['و', 'از', 'طرف', 'دیگر'],\n",
       " ['وزیر', 'آموزش', 'و', 'پرورش'],\n",
       " ['جدید', 'مبتلا', 'به', 'کووید'],\n",
       " ['مالیات', 'بر', 'ارزش', 'افزوده'],\n",
       " ['دو', 'میلیون', 'و', 'هزار'],\n",
       " ['وزیر', 'امور', 'خارجه', 'کشورمان'],\n",
       " ['در', 'بخشی', 'از', 'این'],\n",
       " ['از', 'این', 'است', 'که'],\n",
       " ['در', 'طول', 'این', 'مدت'],\n",
       " ['اشاره', 'به', 'اینکه', 'در'],\n",
       " ['در', 'حالی', 'که', 'در'],\n",
       " ['و', 'به', 'این', 'ترتیب'],\n",
       " ['کووید', 'در', 'کشور', 'شناسایی'],\n",
       " ['آیت\\u200cالله', 'سید', 'ابراهیم', 'رییسی'],\n",
       " ['را', 'به', 'خود', 'اختصاص'],\n",
       " ['نفر', 'از', 'بیماران', 'مبتلا'],\n",
       " ['بر', 'اساس', 'معیارهای', 'قطعی'],\n",
       " ['اساس', 'معیارهای', 'قطعی', 'تشخیصی'],\n",
       " ['تحت', 'مراقبت', 'قرار', 'دارند'],\n",
       " ['نسبت', 'به', 'مدت', 'مشابه'],\n",
       " ['است', 'که', 'در', 'آن'],\n",
       " ['و', 'بر', 'اساس', 'معیارهای'],\n",
       " ['سازمان', 'بازرسی', 'کل', 'کشور'],\n",
       " ['و', 'آن', 'را', 'به'],\n",
       " ['ستاد', 'مقابله', 'با', 'کرونا'],\n",
       " ['من', 'این', 'است', 'که'],\n",
       " ['است', 'در', 'حالی', 'که'],\n",
       " ['خود', 'را', 'در', 'این'],\n",
       " ['در', 'حال', 'افزایش', 'است'],\n",
       " ['که', 'در', 'این', 'زمینه'],\n",
       " ['درصد', 'افزایش', 'یافته', 'است'],\n",
       " ['به', 'همین', 'دلیل', 'هم'],\n",
       " ['شورای', 'عالی', 'انقلاب', 'فرهنگی'],\n",
       " ['بخش', 'دیگری', 'از', 'این'],\n",
       " ['سیاست', 'خارجی', 'اتحادیه', 'اروپا'],\n",
       " ['این', 'بیماری', 'به', 'هزار'],\n",
       " ['بیماران', 'کووید', 'در', 'کشور'],\n",
       " ['دست', 'دادند', 'و', 'مجموع'],\n",
       " ['و', 'در', 'حالی', 'که'],\n",
       " ['با', 'انتشار', 'این', 'تصویر'],\n",
       " ['این', 'سوال', 'که', 'آیا'],\n",
       " ['مجموع', 'بیماران', 'کووید', 'در'],\n",
       " ['کووید', 'در', 'کشور', 'به'],\n",
       " ['بیماری', 'به', 'هزار', 'و'],\n",
       " ['نفر', 'از', 'آن\\u200cها', 'بستری'],\n",
       " ['کووید', 'جان', 'خود', 'را'],\n",
       " ['در', 'حال', 'حاضر', 'در'],\n",
       " ['وزارت', 'صنعت', 'معدن', 'و'],\n",
       " ['هزار', 'و', 'بیمار', 'جدید'],\n",
       " ['به', 'این', 'شرح', 'است'],\n",
       " ['به', 'گزارش', 'خبرگزاری', 'مهر'],\n",
       " ['به', 'هزار', 'میلیارد', 'تومان'],\n",
       " ['مقام', 'معظم', 'رهبری', 'در'],\n",
       " ['این', 'است', 'که', 'اگر'],\n",
       " ['هزار', 'میلیارد', 'تومان', 'از'],\n",
       " ['بیمار', 'کووید', 'جان', 'خود'],\n",
       " ['بیش', 'از', 'هزار', 'میلیارد'],\n",
       " ['در', 'انتخابات', 'ریاست', 'جمهوری'],\n",
       " ['از', 'پیروزی', 'انقلاب', 'اسلامی'],\n",
       " ['انتشار', 'این', 'تصویر', 'نوشت'],\n",
       " ['از', 'آن\\u200cها', 'بستری', 'شدند'],\n",
       " ['آموزش', 'و', 'پرورش', 'در'],\n",
       " ['مجلس', 'شورای', 'اسلامی', 'با'],\n",
       " ['رییس', 'سازمان', 'برنامه', 'و'],\n",
       " ['وزارت', 'فرهنگ', 'و', 'ارشاد'],\n",
       " ['نسبت', 'به', 'سال', 'قبل'],\n",
       " ['همچنین', 'با', 'اشاره', 'به'],\n",
       " ['است', 'و', 'در', 'این'],\n",
       " ['و', 'در', 'حال', 'حاضر'],\n",
       " ['و', 'بیمار', 'جدید', 'مبتلا'],\n",
       " ['به', 'همین', 'دلیل', 'است'],\n",
       " ['این', 'بیانیه', 'آمده', 'است'],\n",
       " ['در', 'گفت\\u200cوگو', 'با', 'ایسنا'],\n",
       " ['گفت\\u200cوگو', 'با', 'خبرگزاری', 'فارس'],\n",
       " ['از', 'بیماران', 'بهبود', 'یافته'],\n",
       " ['نفر', 'از', 'بیماران', 'بهبود'],\n",
       " ['جان', 'باختگان', 'این', 'بیماری'],\n",
       " ['استان', 'سیستان', 'و', 'بلوچستان'],\n",
       " ['و', 'آزمایش', 'تشخیص', 'کووید'],\n",
       " ['رییس', 'شورای', 'شهر', 'تهران'],\n",
       " ['افزود', 'با', 'توجه', 'به'],\n",
       " ['مجموع', 'جان', 'باختگان', 'این'],\n",
       " ['در', 'کشور', 'شناسایی', 'شد'],\n",
       " ['تشخیص', 'کووید', 'در', 'کشور'],\n",
       " ['آزمایش', 'تشخیص', 'کووید', 'در'],\n",
       " ['متاسفانه', 'در', 'طول', 'این'],\n",
       " ['به', 'ذکر', 'است', 'که'],\n",
       " ['هزار', 'و', 'آزمایش', 'تشخیص'],\n",
       " ['باختگان', 'این', 'بیماری', 'به'],\n",
       " ['امر', 'به', 'معروف', 'و'],\n",
       " ['قاچاق', 'کالا', 'و', 'ارز'],\n",
       " ['و', 'مجموع', 'جان', 'باختگان'],\n",
       " ['مجلس', 'شورای', 'اسلامی', 'و'],\n",
       " ['یک', 'میلیارد', 'و', 'میلیون'],\n",
       " ['جمهوری', 'اسلامی', 'ایران', 'به'],\n",
       " ['مبارزه', 'با', 'قاچاق', 'کالا'],\n",
       " ['دادند', 'و', 'مجموع', 'جان'],\n",
       " ['و', 'نهی', 'از', 'منکر'],\n",
       " ['به', 'شرح', 'زیر', 'است'],\n",
       " ['مسیول', 'سیاست', 'خارجی', 'اتحادیه'],\n",
       " ['ستاد', 'ملی', 'مبارزه', 'با'],\n",
       " ['را', 'در', 'این', 'زمینه'],\n",
       " ['معروف', 'و', 'نهی', 'از'],\n",
       " ['همین', 'دلیل', 'است', 'که'],\n",
       " ['میلیارد', 'و', 'میلیون', 'تومان'],\n",
       " ['امور', 'اقتصادی', 'و', 'دارایی'],\n",
       " ['روی', 'کار', 'آمدن', 'دولت'],\n",
       " ['کووید', 'در', 'کشور', 'انجام\\u200cشده\\u200cاست'],\n",
       " ['به', 'معروف', 'و', 'نهی'],\n",
       " ['و', 'با', 'استفاده', 'از'],\n",
       " ['یا', 'از', 'بیمارستان\\u200cها', 'ترخیص'],\n",
       " ['از', 'هر', 'زمان', 'دیگری'],\n",
       " ['عضو', 'شورای', 'شهر', 'تهران'],\n",
       " ['در', 'گفت\\u200cو\\u200cگو', 'با', 'خبرگزاری'],\n",
       " ['اعلام', 'کرده', 'است', 'که'],\n",
       " ['از', 'بیمارستان\\u200cها', 'ترخیص', 'شده\\u200cاند'],\n",
       " ['تهران', 'با', 'اشاره', 'به'],\n",
       " ['از', 'دست', 'داده', 'است'],\n",
       " ['و', 'به', 'تبع', 'آن'],\n",
       " ['هم', 'این', 'است', 'که'],\n",
       " ['طول', 'این', 'مدت', 'بیمار'],\n",
       " ['وزیر', 'ورزش', 'و', 'جوانان'],\n",
       " ['به', 'مدت', 'مشابه', 'سال'],\n",
       " ['به', 'این', 'دلیل', 'که'],\n",
       " ['این', 'مطلب', 'آمده', 'است'],\n",
       " ['آن', 'این', 'است', 'که'],\n",
       " ['در', 'دستور', 'کار', 'خود'],\n",
       " ['شیوع', 'ویروس', 'کرونا', 'در'],\n",
       " ['مقابله', 'با', 'کرونا', 'در'],\n",
       " ['کشور', 'شناسایی', 'شد', 'که'],\n",
       " ['و', 'هزار', 'و', 'آزمایش'],\n",
       " ['جمهوری', 'اسلامی', 'ایران', 'را'],\n",
       " ['در', 'کشور', 'وجود', 'دارد'],\n",
       " ['دیگر', 'این', 'است', 'که'],\n",
       " ['این', 'است', 'که', 'از'],\n",
       " ['دستور', 'کار', 'قرار', 'گرفت'],\n",
       " ['مورد', 'توجه', 'قرار', 'گیرد'],\n",
       " ['تیم', 'ملی', 'فوتبال', 'ایران'],\n",
       " ['در', 'پاسخ', 'به', 'اینکه'],\n",
       " ['شورای', 'شهر', 'تهران', 'در'],\n",
       " ['که', 'از', 'این', 'تعداد'],\n",
       " ['با', 'قاچاق', 'کالا', 'و'],\n",
       " ['نمایندگان', 'مجلس', 'شورای', 'اسلامی'],\n",
       " ['که', 'یکی', 'از', 'آن\\u200cها'],\n",
       " ['با', 'تاکید', 'بر', 'لزوم'],\n",
       " ['بیش', 'از', 'هر', 'زمان'],\n",
       " ['و', 'با', 'اشاره', 'به'],\n",
       " ['جو', 'بایدن', 'رییس\\u200cجمهور', 'آمریکا'],\n",
       " ['به', 'گزارش', 'پایگاه', 'خبری'],\n",
       " ['بخش', 'دیگری', 'از', 'سخنان'],\n",
       " ['ستاد', 'کل', 'نیروهای', 'مسلح'],\n",
       " ['میلیارد', 'و', 'میلیون', 'ریال'],\n",
       " ['افزایش', 'پیدا', 'کرده', 'است'],\n",
       " ['فارس', 'به', 'نقل', 'از'],\n",
       " ['کشور', 'به', 'میلیون', 'و'],\n",
       " ['این', 'در', 'حالی\\u200cبود', 'که'],\n",
       " ['از', 'خروج', 'آمریکا', 'از'],\n",
       " ['دیگری', 'از', 'سخنان', 'خود'],\n",
       " ['و', 'میلیون', 'و', 'هزار'],\n",
       " ['سوال', 'این', 'است', 'که'],\n",
       " ['ارتباطات', 'و', 'فناوری', 'اطلاعات'],\n",
       " ['اما', 'در', 'عین', 'حال'],\n",
       " ['به', 'گزارش', 'خبرگزاری', 'میزان'],\n",
       " ['به', 'گزارش', 'خبرگزاری', 'ایسنا'],\n",
       " ['این', 'مدت', 'بیمار', 'کووید'],\n",
       " ['دارد', 'این', 'است', 'که'],\n",
       " ['است', 'که', 'پس', 'از'],\n",
       " ['در', 'این\\u200cباره', 'به', 'همشهری'],\n",
       " ['تا', 'پیش', 'از', 'این'],\n",
       " ['شد', 'و', 'پس', 'از'],\n",
       " ['گفت', 'در', 'حال', 'حاضر'],\n",
       " ['امنیت', 'ملی', 'و', 'سیاست'],\n",
       " ['مدت', 'بیمار', 'کووید', 'جان'],\n",
       " ['است', 'و', 'به', 'همین'],\n",
       " ['ملی', 'مبارزه', 'با', 'کرونا'],\n",
       " ['بیش', 'از', 'یک', 'میلیون'],\n",
       " ['از', 'میلیون', 'و', 'هزار'],\n",
       " ['با', 'توجه', 'به', 'افزایش'],\n",
       " ['در', 'جلسه', 'علنی', 'دیروز'],\n",
       " ['مبارزه', 'با', 'مواد', 'مخدر'],\n",
       " ['ملی', 'و', 'سیاست', 'خارجی'],\n",
       " ['نشان', 'می\\u200cدهد', 'که', 'در'],\n",
       " ['حضرت', 'امام', 'خمینی', 'ره'],\n",
       " ['در', 'این', 'زمینه', 'به'],\n",
       " ['و', 'نفر', 'از', 'آن\\u200cها'],\n",
       " ['به', 'خارج', 'از', 'کشور'],\n",
       " ['که', 'در', 'سال\\u200cهای', 'اخیر'],\n",
       " ['خارجه', 'جمهوری', 'اسلامی', 'ایران'],\n",
       " ['و', 'در', 'این', 'زمینه'],\n",
       " ['با', 'رعایت', 'پروتکل\\u200cهای', 'بهداشتی'],\n",
       " ['از', 'سوی', 'دیگر', 'در'],\n",
       " ['در', 'فضای', 'مجازی', 'و'],\n",
       " ['در', 'این', 'باره', 'گفت'],\n",
       " ['آمریکا', 'و', 'رژیم', 'صهیونیستی'],\n",
       " ['جمهوری', 'اسلامی', 'ایران', 'با'],\n",
       " ['به', 'گزارش', 'روابط', 'عمومی'],\n",
       " ['در', 'بخش\\u200cهای', 'مراقبت\\u200cهای', 'ویژه'],\n",
       " ['این', 'است', 'که', 'آیا'],\n",
       " ['در', 'چند', 'سال', 'اخیر'],\n",
       " ['این', 'است', 'که', 'چرا'],\n",
       " ['تمام', 'تلاش', 'خود', 'را'],\n",
       " ['است', 'که', 'در', 'سال'],\n",
       " ['در', 'ادامه', 'با', 'اشاره'],\n",
       " ['در', 'ادامه', 'این', 'مطلب'],\n",
       " ['یکی', 'پس', 'از', 'دیگری'],\n",
       " ['با', 'روی', 'کار', 'آمدن'],\n",
       " ['ادامه', 'با', 'اشاره', 'به'],\n",
       " ['در', 'این', 'باره', 'به'],\n",
       " ['کرد', 'و', 'گفت', 'که'],\n",
       " ['با', 'در', 'نظر', 'گرفتن'],\n",
       " ['این', 'گزارش', 'آمده', 'است'],\n",
       " ['تهران', 'با', 'بیان', 'اینکه'],\n",
       " ['شهید', 'و', 'امور', 'ایثارگران'],\n",
       " ['در', 'یک', 'سال', 'گذشته'],\n",
       " ['کمیسیون', 'امنیت', 'ملی', 'و'],\n",
       " ['را', 'تحت', 'تاثیر', 'قرار'],\n",
       " ['میلیون', 'و', 'هزار', 'واحد'],\n",
       " ['کمیسیون', 'برنامه', 'و', 'بودجه'],\n",
       " ['و', 'به', 'نظر', 'می\\u200cرسد'],\n",
       " ['جلسه', 'علنی', 'دیروز', 'مجلس'],\n",
       " ['آموزش', 'و', 'پرورش', 'و'],\n",
       " ['بیماران', 'بهبود', 'یافته', 'یا'],\n",
       " ['بهبود', 'یافته', 'یا', 'از'],\n",
       " ['برای', 'نخستین', 'بار', 'در'],\n",
       " ['به', 'درصد', 'رسیده', 'است'],\n",
       " ['و', 'در', 'این', 'میان'],\n",
       " ['بخش\\u200cهای', 'مراقبت\\u200cهای', 'ویژه', 'بیمارستان\\u200cها'],\n",
       " ['یافته', 'یا', 'از', 'بیمارستان\\u200cها'],\n",
       " ['بازگشت', 'آمریکا', 'به', 'برجام'],\n",
       " ['مدت', 'مشابه', 'سال', 'قبل'],\n",
       " ['را', 'از', 'آن', 'خود'],\n",
       " ['دستور', 'کار', 'خود', 'قرار'],\n",
       " ['و', 'بر', 'این', 'اساس'],\n",
       " ['مراقبت\\u200cهای', 'ویژه', 'بیمارستان\\u200cها', 'تحت'],\n",
       " ['ویژه', 'بیمارستان\\u200cها', 'تحت', 'مراقبت'],\n",
       " ['بیمارستان\\u200cها', 'تحت', 'مراقبت', 'قرار'],\n",
       " ['رییس', 'کل', 'بانک', 'مرکزی'],\n",
       " ['عنوان', 'کرد', 'و', 'گفت'],\n",
       " ['با', 'اشاره', 'به', 'این'],\n",
       " ['وزارت', 'بهداشت', 'درمان', 'و'],\n",
       " ['تاکید', 'کرد', 'و', 'گفت'],\n",
       " ['بیش', 'از', 'هر', 'چیز'],\n",
       " ['در', 'حالی', 'که', 'این'],\n",
       " ['به', 'نقل', 'از', 'یک'],\n",
       " ['بیش', 'از', 'میلیارد', 'دلار'],\n",
       " ['از', 'آن', 'دارد', 'که'],\n",
       " ['درصد', 'افزایش', 'داشته', 'است'],\n",
       " ['مجمع', 'عمومی', 'سازمان', 'ملل'],\n",
       " ['که', 'به', 'نظر', 'می\\u200cرسد'],\n",
       " ['آن', 'است', 'که', 'در'],\n",
       " ['پیش', 'از', 'این', 'هم'],\n",
       " ['جمهوری', 'اسلامی', 'ایران', 'از'],\n",
       " ['است', 'این', 'است', 'که']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [[word2vec_model.wv.index_to_key[x[0][0]], word2vec_model.wv.index_to_key[x[0][1]], word2vec_model.wv.index_to_key[x[0][2]], word2vec_model.wv.index_to_key[x[0][3]]] \n",
    "              for x in sorted(fourword_counts.items(), key = lambda x: x[1], reverse=True)[50:400]]\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "762ba6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in fourword_counts:\n",
    "    if not isinstance(fourword_counts[key], int):\n",
    "        print(key, type(fourword_counts[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c09e4",
   "metadata": {},
   "source": [
    "# make benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11e8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"faspell_main.csv\")\n",
    "# df = df[df[\"error-category\"] != 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9ffcde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_neighbors = {\n",
    "    \"ض\" : [\"ص\", \"ظ\", \"ز\", \"ذ\"],\n",
    "    \"ص\" : [\"ض\", \"ث\"],\n",
    "    \"ث\" : [\"ص\", \"ق\"],\n",
    "    \"ق\" : [\"ف\", \"ث\", \"غ\"],\n",
    "    \"ف\" : [\"ق\", \"غ\"],\n",
    "    \"غ\" : [\"ف\", \"ه\", \"ق\"],\n",
    "    \"ع\" : [\"غ\", \"ه\"],\n",
    "    \"ه\" : [\"ع\", \"خ\", \"ح\"],\n",
    "    \"خ\" : [\"ه\", \"ح\"],\n",
    "    \"ح\" : [\"خ\", \"ج\", \"ه\"],\n",
    "    \"ج\" : [\"ح\", \"چ\"],\n",
    "    \"چ\" : [\"ج\", \"پ\"],\n",
    "    \"پ\" : [\"چ\", \"ب\"],\n",
    "    \"ش\" : [\"س\"],\n",
    "    \"س\" : [\"ش\", \"ی\"],\n",
    "    \"ی\" : [\"س\", \"ب\"],\n",
    "    \"ب\" : [\"ی\", \"ل\"],\n",
    "    \"ل\" : [\"ب\", \"ا\", \"آ\"],\n",
    "    \"ا\" : [\"ل\", \"ت\"],\n",
    "    \"آ\" : [\"ل\", \"ت\"],\n",
    "    \"ت\" : [\"ا\", \"ن\", \"ط\", \"آ\"],\n",
    "    \"ن\" : [\"ت\", \"م\"],\n",
    "    \"م\" : [\"ن\", \"ک\"],\n",
    "    \"ک\" : [\"م\", \"گ\"],\n",
    "    \"گ\" : [\"ک\"],\n",
    "    \"ظ\" : [\"ط\", \"ض\", \"ز\", \"ذ\"],\n",
    "    \"ط\" : [\"ظ\", \"ز\", \"ت\"],\n",
    "    \"ز\" : [\"ط\", \"ض\", \"ر\", \"ذ\"],\n",
    "    \"ژ\" : [\"ط\", \"ر\"],\n",
    "    \"ر\" : [\"ز\", \"ذ\"],\n",
    "    \"ذ\" : [\"ر\", \"ض\", \"د\", \"ذ\"],\n",
    "    \"د\" : [\"ذ\", \"ی\"],\n",
    "    \"و\" : [\"د\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e757d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaceble_characters = [\"و\", \"ن\", \"م\", \"ل\", \"گ\", \"ک\", \"ق\", \"ف\", \"غ\", \"ع\", \"ظ\", \"ط\", \"ض\", \"ص\", \"ی\", \"ه\",\n",
    "#                         \"ش\", \"س\", \"ژ\", \"ز\", \"ر\", \"ذ\", \"د\", \"خ\", \"ح\", \"چ\", \"ج\", \"ث\", \"ت\", \"پ\", \"ب\", \"ا\", \"آ\"]\n",
    "\n",
    "replaceble_characters = list(character_neighbors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806733fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [word2vec_model.wv.index_to_key[x[0][0]] for x in sorted(word_counts.items(), key = lambda x: x[1], reverse=True)[1:20]]\n",
    "stop_words_indices = [word2vec_model.wv.key_to_index[x] for x in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7f82d",
   "metadata": {},
   "source": [
    "# random errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879bf2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_character_to_replace(character, close_change):\n",
    "    if close_change:\n",
    "        return random.choice(character_neighbors[character])\n",
    "    else:\n",
    "        return random.choice(list(set(replaceble_characters)-(set(character_neighbors[character]+[character]))))\n",
    "    \n",
    "def replace_character(phrase, location, close_change):\n",
    "    char = select_character_to_replace(phrase[location], close_change)\n",
    "    return phrase[:location] + char + phrase[location+1:]\n",
    "\n",
    "def del_character(phrase, location, close_change):\n",
    "    return phrase[:location] + phrase[location+1:]\n",
    "\n",
    "def add_character(phrase, location, close_change):\n",
    "    char = select_character_to_replace(phrase[location], close_change)\n",
    "    return phrase[:location] + char + phrase[location:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e9e2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_error_function = {\n",
    "    0:replace_character,\n",
    "    1:del_character,\n",
    "    2:add_character\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1ff183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 for replacement, 1 for deletion, 2 for addition\n",
    "def word_random_change(word, distance, close_change):\n",
    "    \n",
    "    while True:\n",
    "        locations = random.sample(range(len(word)), k=min(distance, len(word)))\n",
    "        if sum([word[location] in replaceble_characters for location in locations])==len(locations):\n",
    "            break\n",
    "\n",
    "    locations = np.array(sorted(locations))\n",
    "    changes = []\n",
    "    for i in range(len(locations)):\n",
    "        random_edit = random.randint(0, 2)\n",
    "        word = index_to_error_function[random_edit](word, locations[i], close_change)\n",
    "        if random_edit == 1:\n",
    "            if i != len(locations):\n",
    "                locations[i+1:] -= 1\n",
    "        elif random_edit == 2:\n",
    "            if i != len(locations):\n",
    "                locations[i+1:] += 1\n",
    "        changes.append(random_edit)\n",
    "    return word, changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a96b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_random_error(phrase, number_of_errors, number_of_words_with_error, close_change):\n",
    "    words = tokenizer.tokenize_words(normalizer.normalize(phrase))\n",
    "    final_words = []\n",
    "    final_changes = []\n",
    "    error_words_indices = random.sample(range(len(words)), k=number_of_words_with_error)\n",
    "    error_words_indices = error_words_indices + random.choices(error_words_indices, k=number_of_errors-number_of_words_with_error)\n",
    "    error_words_indices, word_error_counts = np.unique(error_words_indices, return_counts=True)\n",
    "    for i in range(len(error_words_indices)):\n",
    "        if sum([character in replaceble_characters for character in words[error_words_indices[i]]])<word_error_counts[i]:\n",
    "            return None, None\n",
    "    for i in range(len(words)):\n",
    "        if i in error_words_indices:\n",
    "            error, changes = word_random_change(words[i], word_error_counts[np.where(error_words_indices==i)[0][0]], close_change)\n",
    "            final_words.append(error)\n",
    "            final_changes.append(changes)\n",
    "        else:\n",
    "            final_words.append(words[i])\n",
    "            final_changes.append([])\n",
    "            \n",
    "    return \" \".join(final_words), final_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9212ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_error(counts, model, from_top=10000, k=500, max_error_word=2, max_error_num=3, ngram_given=False):\n",
    "    if not ngram_given:\n",
    "        randomly_chosen_ngrams = random.sample([x[0] for x in sorted(counts.items(), key=lambda x: x[1], reverse=True)[1:from_top] if \n",
    "                                             sum([y in stop_words_indices for y in x[0]])==0], k=300)\n",
    "        randomly_chosen_ngrams = [\" \".join([word2vec_model.wv.index_to_key[y] for y in x]) for x in randomly_chosen_ngrams]\n",
    "        \n",
    "    else:\n",
    "        randomly_chosen_ngrams = counts\n",
    "    df = pd.DataFrame({'correct word':[], \"misspelled word\":[], \"total edit distance\":[], \n",
    "                       \"number of words with error\":[], \"close change\": [], \"changes\":[]})\n",
    "    for ngram in randomly_chosen_ngrams:\n",
    "        for error_num in range(1, max_error_num+1):\n",
    "            for errored_word_num in range(1, min(error_num+1, max_error_num, max_error_word+1)):\n",
    "                for close_change in [False, True]:\n",
    "    #                 print(biword, error_num, errored_word_num, close_change)\n",
    "                    for i in range(3):\n",
    "                        try:\n",
    "                            misspelled_phrase, changes = phrase_random_error(ngram,error_num, errored_word_num, close_change)\n",
    "                            if misspelled_phrase==None:\n",
    "                                continue\n",
    "                            if levenshtein(misspelled_phrase, ngram) == error_num:\n",
    "                                df = df.append(pd.DataFrame({'correct word':ngram, 'misspelled word': misspelled_phrase,\n",
    "                                                             'total edit distance':error_num, 'number of words with error':errored_word_num,\n",
    "                                                             'close change':close_change, 'changes':[changes]})).reset_index(drop=True)\n",
    "                                break\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            print(ngram)\n",
    "                            print(error_num)\n",
    "                            print(errored_word_num)\n",
    "                            raise Exception()\n",
    "                            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac2cc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = list(pd.read_excel(\"handmade words.xlsx\")[\"correct word\"])\n",
    "handmade_mistakes_df = make_random_error(ngrams, None, from_top=10000, k=500, max_error_word=2, max_error_num=3, ngram_given=True)\n",
    "handmade_mistakes_df.to_csv(\"handmade mistakes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "189d8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_random_error_df = make_random_error(biword_counts, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c1f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "threegram_random_error_df = make_random_error(threeword_counts, word2vec_model, from_top=10000, k=500, \n",
    "                                    max_error_word=3, max_error_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53aa6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(bigram_random_error_df))\n",
    "# bigram_random_error_df.sample(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ba7e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgram_random_error_df = make_random_error(fourword_counts, word2vec_model, from_top=10000, k=500, \n",
    "                                    max_error_word=3, max_error_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17682aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word, misspelled word, edit distance, number of words with error, close_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f913128",
   "metadata": {},
   "source": [
    "# homophonic error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bc803653",
   "metadata": {},
   "outputs": [],
   "source": [
    "homophonic_letters = {\n",
    "    \"ض\":\n",
    "        [\"ظ\", \"ز\", \"ذ\"],\n",
    "    \"ص\":\n",
    "        [\"س\", \"ث\"],\n",
    "    \"ث\":\n",
    "        [\"س\", \"ص\"],\n",
    "    \"ق\":\n",
    "        [\"غ\"],\n",
    "    \"غ\":\n",
    "        [\"ق\"],\n",
    "    \"ه\":\n",
    "        [\"ح\"],\n",
    "    \"ح\":\n",
    "        [\"ه\"],\n",
    "    \"س\":\n",
    "        [\"ث\", \"ص\"],\n",
    "    \"ت\":\n",
    "        [\"ط\"],\n",
    "    \"ظ\":\n",
    "        [\"ض\", \"ز\", \"ذ\"],\n",
    "    \"ط\":\n",
    "        [\"ت\"],\n",
    "    \"ز\":\n",
    "        [\"ض\", \"ظ\", \"ذ\"],\n",
    "    \"ذ\":\n",
    "        [\"ض\", \"ز\", \"ظ\"],\n",
    "}\n",
    "homophonic_letters_in_one_string = \"ضصثقغهحستظطزذ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "847a68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_homophonic_error(phrase, error_num):\n",
    "    phrase_homophonic_letters_indices = [i for i in range(len(phrase)) if phrase[i] in homophonic_letters_in_one_string]\n",
    "    if error_num > len(phrase_homophonic_letters_indices):\n",
    "        return None\n",
    "    phrase_homophonic_letters_indices = random.sample(phrase_homophonic_letters_indices, k=error_num)\n",
    "    phrase_homophonic_letters_indices = list(sorted(phrase_homophonic_letters_indices))\n",
    "    phrase_ranges = []\n",
    "    if phrase_homophonic_letters_indices[0] != 0:\n",
    "        phrase_ranges.append([phrase[0:phrase_homophonic_letters_indices[0]]])\n",
    "    phrase_ranges.append([phrase[phrase_homophonic_letters_indices[0]]] + \n",
    "                     homophonic_letters[phrase[phrase_homophonic_letters_indices[0]]])\n",
    "    for i in range(1, len(phrase_homophonic_letters_indices)):\n",
    "        phrase_ranges.append([phrase[phrase_homophonic_letters_indices[i-1]+1:phrase_homophonic_letters_indices[i]]])\n",
    "        phrase_ranges.append([phrase[phrase_homophonic_letters_indices[i]]]+homophonic_letters[phrase[phrase_homophonic_letters_indices[i]]])\n",
    "    if phrase_homophonic_letters_indices[-1] != len(phrase)-1:\n",
    "        phrase_ranges.append([phrase[phrase_homophonic_letters_indices[-1]+1:]])\n",
    "    res = list(itertools.product(*phrase_ranges))\n",
    "#     return res\n",
    "\n",
    "    return [\"\".join(x) for x in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "77975504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_homophonic_errors(counts, model, from_top=10000, k=500):\n",
    "    df = pd.DataFrame()\n",
    "    randomly_chosen_ngrams = random.sample([x[0] for x in sorted(counts.items(), key=lambda x: x[1], reverse=True)[1:from_top] if \n",
    "                                            sum([len(set(model.wv.index_to_key[y])&set(homophonic_letters_in_one_string))>0 for y in x[0]])>0], k=k)\n",
    "    randomly_chosen_ngrams = [\" \".join([word2vec_model.wv.index_to_key[y] for y in x]) for x in randomly_chosen_ngrams] \n",
    "    \n",
    "    df = pd.DataFrame({'correct word':[], \"misspelled word\":[], \"total edit distance\":[], \n",
    "                   \"number of words with error\":[], \"close change\": [], \"changes\":[]})\n",
    "    for phrase in randomly_chosen_ngrams:\n",
    "        phrases_homophobable_chars_num = sum([x in homophonic_letters_in_one_string for x in phrase])\n",
    "        for i in range(1, phrases_homophobable_chars_num+1):\n",
    "            errored_phrases = list(set(phrase_homophonic_error(phrase, i))-set([phrase]))\n",
    "            for errored_phrase in errored_phrases:\n",
    "                df = df.append(pd.DataFrame({'correct word':[phrase], \"misspelled word\":[errored_phrase], \n",
    "                                             \"total edit distance\":[levenshtein(phrase, errored_phrase)], \n",
    "                               \"number of words with error\":[None], \"close change\": [True], \"changes\":[0]})).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "453c2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "homophonic_df = make_homophonic_errors(biword_counts, word2vec_model, k=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b27324d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2801\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct word</th>\n",
       "      <th>misspelled word</th>\n",
       "      <th>total edit distance</th>\n",
       "      <th>number of words with error</th>\n",
       "      <th>close change</th>\n",
       "      <th>changes</th>\n",
       "      <th>none word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>درخصوص این</td>\n",
       "      <td>درخثوس این</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>درخصوص این</td>\n",
       "      <td>درخثوص این</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>خود هستند</td>\n",
       "      <td>خود حثتند</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>بسته است</td>\n",
       "      <td>بثطه اصط</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>در نزدیکی</td>\n",
       "      <td>در نذدیکی</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>کاهش ارزش</td>\n",
       "      <td>کاحش ارظش</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>صیانت از</td>\n",
       "      <td>سیانت اذ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>هنری و</td>\n",
       "      <td>حنری و</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>موظف است</td>\n",
       "      <td>موذف اصت</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>گزارش داده</td>\n",
       "      <td>گزارش دادح</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>دولت گذشته</td>\n",
       "      <td>دولط گزشطه</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>که نباید</td>\n",
       "      <td>کح نباید</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>اتفاقاتی که</td>\n",
       "      <td>اتفاقاتی کح</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>باشگاه استقلال</td>\n",
       "      <td>باشگاه اثطقلال</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>به‌طور طبیعی</td>\n",
       "      <td>بح‌طور طبیعی</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        correct word misspelled word  total edit distance  \\\n",
       "2024      درخصوص این      درخثوس این                  2.0   \n",
       "2026      درخصوص این      درخثوص این                  1.0   \n",
       "1699       خود هستند       خود حثتند                  2.0   \n",
       "1434        بسته است        بثطه اصط                  4.0   \n",
       "367        در نزدیکی       در نذدیکی                  1.0   \n",
       "1712       کاهش ارزش       کاحش ارظش                  2.0   \n",
       "1717        صیانت از        سیانت اذ                  2.0   \n",
       "1073          هنری و          حنری و                  1.0   \n",
       "1512        موظف است        موذف اصت                  2.0   \n",
       "357       گزارش داده      گزارش دادح                  1.0   \n",
       "628       دولت گذشته      دولط گزشطه                  3.0   \n",
       "2114        که نباید        کح نباید                  1.0   \n",
       "907      اتفاقاتی که     اتفاقاتی کح                  1.0   \n",
       "1185  باشگاه استقلال  باشگاه اثطقلال                  2.0   \n",
       "699     به‌طور طبیعی    بح‌طور طبیعی                  1.0   \n",
       "\n",
       "     number of words with error close change  changes  none word  \n",
       "2024                       None         True      0.0       True  \n",
       "2026                       None         True      0.0       True  \n",
       "1699                       None         True      0.0       True  \n",
       "1434                       None         True      0.0       True  \n",
       "367                        None         True      0.0       True  \n",
       "1712                       None         True      0.0       True  \n",
       "1717                       None         True      0.0       True  \n",
       "1073                       None         True      0.0       True  \n",
       "1512                       None         True      0.0       True  \n",
       "357                        None         True      0.0       True  \n",
       "628                        None         True      0.0       True  \n",
       "2114                       None         True      0.0       True  \n",
       "907                        None         True      0.0       True  \n",
       "1185                       None         True      0.0       True  \n",
       "699                        None         True      0.0       True  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(homophonic_df))\n",
    "homophonic_df.sample(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "61748a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noneword, word error column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1379ff8",
   "metadata": {},
   "source": [
    "# add noneword change column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f952c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noneword_column(model, df):\n",
    "    noneword_column = []\n",
    "    for i in range(len(df)):\n",
    "        tokenized_words=tokenizer.tokenize_words(normalizer.normalize(df.loc[i, \"misspelled word\"]))\n",
    "        if sum([x in model.wv.key_to_index for x in tokenized_words]) == len(tokenized_words):\n",
    "            noneword_column.append(False)\n",
    "        else:\n",
    "            noneword_column.append(True)\n",
    "    return noneword_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e208c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_homophonic_df[\"none word\"] = get_noneword_column(word2vec_model, bigram_homophonic_df)\n",
    "bigram_random_error_df[\"none word\"] = get_noneword_column(word2vec_model, bigram_random_error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54423193",
   "metadata": {},
   "outputs": [],
   "source": [
    "threegram_homophonic_df[\"none word\"] = get_noneword_column(word2vec_model, threegram_homophonic_df)\n",
    "threegram_random_error_df[\"none word\"] = get_noneword_column(word2vec_model, threegram_random_error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "747eaf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgram_homophonic_df[\"none word\"] = get_noneword_column(word2vec_model, fourgram_homophonic_df)\n",
    "fourgram_random_error_df[\"none word\"] = get_noneword_column(word2vec_model, fourgram_random_error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35abf2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_random_error_df.to_csv(\"random bigram.csv\")\n",
    "threegram_random_error_df.to_csv(\"random threegram.csv\")\n",
    "fourgram_random_error_df.to_csv(\"random fourgram.csv\")\n",
    "\n",
    "bigram_random_error_df.to_csv(\"homophonics bigram.csv\")\n",
    "threegram_random_error_df.to_csv(\"homophonics threegram.csv\")\n",
    "fourgram_random_error_df.to_csv(\"homophonics fourgram.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
