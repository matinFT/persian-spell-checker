{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba66986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "import parsivar\n",
    "import json\n",
    "import pickle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3097578",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = parsivar.Normalizer()\n",
    "tokenizer = parsivar.Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ae818",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4b8ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237915404 characters\n",
      "2106953 lines\n"
     ]
    }
   ],
   "source": [
    "f = open(\"test.txt\", \"r\", encoding='utf-8')\n",
    "number_of_chars = len(f.read())\n",
    "print(f'{number_of_chars} characters')\n",
    "f.close()\n",
    "f = open(\"test.txt\", \"r\", encoding='utf-8')\n",
    "number_of_lines = len(f.readlines())\n",
    "print(f'{number_of_lines} lines')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260481a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences():\n",
    "    sentences = []\n",
    "    with open(\"test.txt\", \"r\", encoding='utf-8') as t:\n",
    "        while True:\n",
    "            line = t.readline()\n",
    "            if line == \"\":\n",
    "                break\n",
    "            sentences.append(tokenizer.tokenize_words(line))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b629314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = get_sentences()\n",
    "# print(len(sentences))\n",
    "# 4GB of RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960679c2",
   "metadata": {},
   "source": [
    "# fastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05cde8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastText_model = FastText.load(\"FastTextModel\")\n",
    "# 3.5GB RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c253f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FastText_model = FastText(vector_size=300, window=5, min_count=1, sentences=sentences, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastText_model.wv.most_similar(FastText_model.wv['شاه'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100ec60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastText_model.save(\"FastTextModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fddf879",
   "metadata": {},
   "source": [
    "# Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54def8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load(\"Word2VecModel\")\n",
    "# 1GB RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a15ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "word2vec_model = Word2Vec(vector_size=300, window=5, min_count=1, sentences=sentences, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0a55b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('مرد', 1.0),\n",
       " ('زن', 0.6828464865684509),\n",
       " ('شوهر', 0.6612272262573242),\n",
       " ('مردی', 0.6603354811668396),\n",
       " ('دختر', 0.6036628484725952),\n",
       " ('دختری', 0.5984135270118713),\n",
       " ('میانسال', 0.5959803462028503),\n",
       " ('شوهری', 0.5932475328445435),\n",
       " ('پیرزن', 0.5812994837760925),\n",
       " ('پیرمرد', 0.5786240100860596)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(word2vec_model.wv['مرد'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63ddcb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.524875283241272"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.distance(\"شاه\", \"ملکه\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b486f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.save(\"Word2VecModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94412a23",
   "metadata": {},
   "source": [
    "# Build Ngram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7cb8d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_tuple(words, model):\n",
    "    return tuple([model.wv.key_to_index[words[i]] for i in range(len(words))])\n",
    "\n",
    "# seems some of the words in the text file is not present in model key_to_index\n",
    "def build_ngrams(n):\n",
    "    ngram_counts = {}\n",
    "    with open(\"test.txt\", \"r\", encoding='utf-8') as t:\n",
    "        while True:\n",
    "            line = t.readline()\n",
    "            if line == \"\":\n",
    "                break\n",
    "            words = tokenizer.tokenize_words(line)\n",
    "            for i in range(max(len(words)-n+1, 0)):\n",
    "                try:\n",
    "#                     pre_words_indices = tuple([word2vec_model.wv.key_to_index[words[i+j]] for j in range(n)])\n",
    "                    pre_words_indices = words_to_tuple(words[i:i+n], word2vec_model)\n",
    "                    if pre_words_indices in ngram_counts:\n",
    "                        ngram_counts[pre_words_indices] += 1\n",
    "                    else:\n",
    "                        ngram_counts[pre_words_indices] = 0\n",
    "                except:\n",
    "                    pass\n",
    "    return ngram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "703235f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_counts = build_ngrams(1)\n",
    "word_counts[\"all\"] = sum(word_counts.values())\n",
    "# 100MB of RAM\n",
    "biword_counts = build_ngrams(2)\n",
    "biword_counts[\"all\"] = sum(biword_counts.values())\n",
    "# 700MB of RAM\n",
    "threeword_counts = build_ngrams(3)\n",
    "threeword_counts[\"all\"] = sum(threeword_counts.values())\n",
    "# 1.6GB of RAM\n",
    "fourword_counts = build_ngrams(4)\n",
    "fourword_counts[\"all\"] = sum(fourword_counts.values())\n",
    "# 3.5GB of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8f8d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word counts.json', 'wb') as f:\n",
    "    pickle.dump(word_counts, f)\n",
    "with open('bi-grams.json', 'wb') as f:\n",
    "    pickle.dump(biword_counts, f)\n",
    "with open('three-grams.json', 'wb') as f:\n",
    "    pickle.dump(threeword_counts, f)\n",
    "with open('four-grams.json', 'wb') as f:\n",
    "    pickle.dump(fourword_counts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "288bd07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words:       347680\n",
      "bi-grams:    6764724\n",
      "three-grams: 20208193\n",
      "four-grams:  29157652\n"
     ]
    }
   ],
   "source": [
    "print(f'words:       {len(word_counts)}')\n",
    "print(f'bi-grams:    {len(biword_counts)}')\n",
    "print(f'three-grams: {len(threeword_counts)}')\n",
    "print(f'four-grams:  {len(fourword_counts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca61aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word counts.json', 'rb') as f:\n",
    "    word_counts = pickle.load(f)\n",
    "    f.close()\n",
    "with open('bi-grams.json', 'rb') as f:\n",
    "    biword_counts = pickle.load(f)\n",
    "    f.close()\n",
    "with open('three-grams.json', 'rb') as f:\n",
    "    threeword_counts = pickle.load(f)\n",
    "    f.close()\n",
    "# with open('four-grams.json', 'rb') as f:\n",
    "#     fourword_counts = pickle.load(f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46479e50",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6371ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850352c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_score(model, query_words, proposed_words, word_counts, biword_counts, threeword_counts, fourword_counts=None, weights=[1,1,1,1]):\n",
    "    S0_scores = []\n",
    "    S1_scores = []\n",
    "    S2_scores = []\n",
    "    S3_scores = []\n",
    "    for i in range(len(proposed_words)):\n",
    "        # OOV penalty?\n",
    "        counts = word_counts.get((model.wv.key_to_index.get(proposed_words[i], None), ), None)\n",
    "        if counts is None:\n",
    "            S0_scores.append(1/word_counts[\"all\"])\n",
    "        else:\n",
    "            S0_scores.append(counts/word_counts[\"all\"])\n",
    "        if i >= 1:\n",
    "            key = (model.wv.key_to_index.get(proposed_words[i-1], None), model.wv.key_to_index.get(proposed_words[i], None))\n",
    "            counts = biword_counts.get(key, None)\n",
    "            if counts is None:\n",
    "                S1_scores.append(1/biword_counts[\"all\"])\n",
    "            else:\n",
    "                key = (model.wv.key_to_index.get(proposed_words[i-1], None), )\n",
    "                S1_scores.append(counts/word_counts[key])\n",
    "        \n",
    "        if i >= 2:\n",
    "            key = (model.wv.key_to_index.get(proposed_words[i-2], None), model.wv.key_to_index.get(proposed_words[i-1], None), model.wv.key_to_index.get(proposed_words[i], None))\n",
    "            counts = threeword_counts.get(key, None)\n",
    "            if counts is None:\n",
    "                S2_scores.append(1/threeword_counts[\"all\"])\n",
    "            else:\n",
    "                key = (model.wv.key_to_index.get(proposed_words[i-2], None), model.wv.key_to_index.get(proposed_words[i-1], None))\n",
    "                S2_scores.append(counts/biword_counts[key])\n",
    "        \n",
    "#         if i >= 3:\n",
    "#             key = (model.wv.key_to_index.get(proposed_words[i-3], None), model.wv.key_to_index.get(proposed_words[i-2], None),\n",
    "#                    model.wv.key_to_index.get(proposed_words[i-1], None), model.wv.key_to_index.get(proposed_words[i], None))\n",
    "#             counts = fourword_counts.get(key, None)\n",
    "#             if counts is None:\n",
    "#                 S3_scores.append(1/fourword_counts[\"all\"])\n",
    "#             else:\n",
    "#                 key = (model.wv.key_to_index.get(proposed_words[i-3], None), model.wv.key_to_index.get(proposed_words[i-2], None),\n",
    "#                        model.wv.key_to_index.get(proposed_words[i-1], None))\n",
    "#                 S3_scores.append(counts/threeword_counts[key])\n",
    "\n",
    "    return weights[0]*sum(S0_scores)+weights[1]*sum(S1_scores)+weights[2]*sum(S2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e0c5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006941245437847378\n",
      "0.0006941011088625792\n"
     ]
    }
   ],
   "source": [
    "query_words = [\"جلوم\", \"وزیر\"]\n",
    "proposed_words = [\"غلوم\", \"وزیر\"]\n",
    "print(cal_score(word2vec_model, query_words, proposed_words, word_counts, biword_counts, threeword_counts))\n",
    "print(cal_score(word2vec_model, query_words, query_words, word_counts, biword_counts, threeword_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73a6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_word_candidates(model, query_words):\n",
    "    res = [[x for x in model.wv.key_to_index if editdistance.eval(x, query_words[i]) <= 1] for i in range(len(query_words))]\n",
    "    return list(itertools.product(*res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8580c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_answere(model, query):\n",
    "    query_words = tokenizer.tokenize_words(normalizer.normalize(query))\n",
    "    candidates = cal_word_candidates(model, query_words)\n",
    "    \n",
    "    res = \"\"\n",
    "    score = 0\n",
    "    for candidate in candidates:\n",
    "        temp_score = cal_score(word2vec_model, query_words, candidate, word_counts, biword_counts, threeword_counts)\n",
    "        if temp_score > score:\n",
    "            score = temp_score\n",
    "            res = candidate \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78a24a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('قله', 'دماوند')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_answere(word2vec_model, \"غله دماوند\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f74773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(a, b):\n",
    "    if len(a) == 0:\n",
    "        return len(b)\n",
    "    if len(b) == 0:\n",
    "        return len(a)\n",
    "    if a[0] == b[0]:\n",
    "        return edit_distance(a[1:], b[1:])\n",
    "    else:\n",
    "        return 1+(min(edit_distance(a, b[1:]), edit_distance(a[1:], b)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
